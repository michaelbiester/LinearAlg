{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c905a59e-2afc-4c25-9e0e-b2479615a55a",
   "metadata": {},
   "source": [
    "# Mean, Variance, Correlation and Covariance\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "First a review of the **1-dimensional** case. Later the process is repeated for the multivariate case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f772b69-63e3-4128-90d6-4604543d6d69",
   "metadata": {},
   "source": [
    "# Sample Mean\n",
    "\n",
    "We have a measurement $X$ of `n` samples $x_1, \\dots, \\ x_n$. The mean / mean value is the defined as the average:\n",
    "\n",
    "$$\n",
    "E(X) = \\frac{1}{n} \\sum_{j=1}^{n} x_j\n",
    "$$\n",
    "\n",
    "If we choose to arrage samples into a column vector $\\mathbf{x}$ \n",
    "\n",
    "$$\n",
    "\\mathbf{x} = \\left[\\begin{array}{c}\n",
    "x_1 \\\\ \\vdots \\\\ x_n\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "we can write\n",
    "\n",
    "$$\n",
    "E(\\mathbf{x}) = \\frac{1}{n} \\sum_{j=1}^{n} x_j\n",
    "$$\n",
    "\n",
    "The mean value of the squared elements $x_1^2, \\dots, \\ x_n^2$ is computed from\n",
    "\n",
    "$$\n",
    "E(X^2) = \\frac{1}{n} \\sum_{j=1}^{n} x_j^2\n",
    "$$\n",
    "\n",
    "or using data $\\mathbf{x}$ arranged in a column vector:\n",
    "\n",
    "$$\n",
    "E(X^2) = \\frac{1}{n} \\mathbf{x}^T \\cdot \\mathbf{x}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Sample Variance\n",
    "\n",
    "$$\\begin{gather}\n",
    "E((X - E(X))^2 = \\frac{1}{n} \\sum_{j=1}^{n} \\left(x_j - E(X)\\right)^2 \\\\\n",
    "\\ = \\frac{1}{n} \\sum_{j=1}^{n} x_j^2 - 2 \\frac{1}{n} \\sum_{j=1}^{n} x_j \\cdot E(X) + \\frac{1}{n} \\sum_{j=1}^{n} E(X)^2 \\\\\n",
    "\\to \\\\\n",
    "E((X - E(X))^2 = E(X^2) - E(X)^2\n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e338e1f8-faa9-43ed-8bed-f04928c813d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57f9f1e8-c8fc-44ae-ae32-870e457958d9",
   "metadata": {},
   "source": [
    "## Mean / Expectation of a vector\n",
    "\n",
    "From `N` measurements each measurement produces a *data point* of `K` items.\n",
    "\n",
    "We assume that the `j` th measurement yields a data point that is represented as a row vector $\\mathbf{d}_j^T$\n",
    "\n",
    "$$\n",
    "\\mathbf{d}_j^T = \\left[\\begin{array}{ccc}\n",
    "d_{j,\\ 1} & \\cdots & d_{j,\\ K}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "We will arrange the `N` measurements into a *data matrix* $\\mathbf{D} : \\in \\mathbb{R}^{N \\times K}$:\n",
    "\n",
    "$$\n",
    "\\mathbf{D} = \\left[\\begin{array}{cccc}\n",
    "d_{1,\\ 1} & d_{1,\\ 2} & \\cdots & d_{1,\\ K} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "d_{j,\\ 1} & d_{j,\\ 2} & \\cdots & d_{j,\\ K} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "d_{N,\\ 1} & d_{N,\\ 2} & \\cdots & d_{N,\\ K}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Each row of $\\mathbf{D}$ represents a single measurement of `K` items (eg.: temperature, time, voltage, speed, ...).\n",
    "\n",
    "The `i-th` column vector $\\mathbf{d}_{j:,\\ i}$ of $\\mathbf{D}$ contains all measurements of the `i-th` measurement item (eg: temperature).\n",
    "\n",
    "Hence the mean value of the `i-th` measurement item is just the mean value of the elements of column vector $\\mathbf{d}_{j:,\\ i}$:\n",
    "\n",
    "$$\n",
    "E(\\mathbf{d}_{j:,\\ i}) = \\frac{1}{N} \\sum_{j=1}^N d_{j, i}\n",
    "$$\n",
    "\n",
    "\n",
    "In some cases it is necessary to remove the mean value of each data column from its data column to obtain the *centered* data matrix $\\mathbf{\\overline{D}}$\n",
    "\n",
    "$$\n",
    "\\mathbf{\\overline{D}} = \\left[\\begin{array}{cccc}\n",
    "\\left(d_{1,\\ 1} - E(\\mathbf{d}_{j:,\\ 1})\\right) & \\left(d_{1,\\ 2} - E(\\mathbf{d}_{j:,\\ 2})\\right) &  \\cdots & \\left(d_{1,\\ K} - E(\\mathbf{d}_{j:,\\ K})\\right) \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "\\left(d_{j,\\ 1} - E(\\mathbf{d}_{j:,\\ 1})\\right)  & \\left(d_{j,\\ 2} - E(\\mathbf{d}_{j:,\\ 2})\\right) &  \\cdots & \\left(d_{j,\\ K} - E(\\mathbf{d}_{j:,\\ K})\\right) \\\\\n",
    "\\vdots & \\vdots & \\vdots \\\\\n",
    "\\left(d_{N,\\ 1} - E(\\mathbf{d}_{j:,\\ 1})\\right) & \\left(d_{N,\\ 2} - E(\\mathbf{d}_{j:,\\ 2})\\right) &  \\cdots & \\left(d_{N,\\ K} - E(\\mathbf{d}_{j:,\\ K})\\right)\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651dc2ca-9f40-4bc9-9e04-dc3b7f18f01f",
   "metadata": {},
   "source": [
    "### Random Vector\n",
    "\n",
    "$\\mathbf{x} : \\ \\in \\mathbb{R}^{K}$ .\n",
    "\n",
    "$$\n",
    "\\mathbf{x} = \\left[\\begin{array}{c}\n",
    "x_1 \\\\ \\vdots \\\\ x_i \\\\ \\vdots \\\\ x_K\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Now we assume there are `N` realisation of such a random vector. We denote the `j-th` realisation by $\\mathbf{x}_j$ and its elements / components by:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_j = \\left[\\begin{array}{c}\n",
    "x_{1,j} \\\\ \\vdots \\\\ x_{i,j} \\\\ \\vdots \\\\ x_{K,j}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "We define the expectation $E(\\mathbf{x}$ of these `N` random vector element-wise like this:\n",
    "\n",
    "$$\n",
    "E(\\mathbf{x}) = \\frac{1}{N} \\sum_{j=1}^N \\mathbf{x}_j = \\left[\\begin{array}{c}\n",
    "\\frac{1}{N} \\sum_{j=1}^N x_{1,j} \\\\ \\vdots \\\\ \\frac{1}{N} \\sum_{j=1}^N x_{i,j} \\\\ \\vdots \\\\ \\frac{1}{N} \\sum_{j=1}^N x_{K,j}\n",
    "\\end{array}\\right] = \\left[\\begin{array}{c}\n",
    "\\overline{x}_{1} \\\\ \\vdots \\\\ \\overline{x}_{i} \\\\ \\vdots \\\\ \\overline{x}_{K}\n",
    "\\end{array}\\right] = \\left[\\begin{array}{c}\n",
    "E(x_{1}) \\\\ \\vdots \\\\ E(x_{i}) \\\\ \\vdots \\\\ E(x_{K})\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Now we consider the matrix equation \n",
    "\n",
    "$$\n",
    "\\mathbf{y} = \\mathbf{A} \\cdot \\mathbf{x} + \\mathbf{b} : \\ \\mathbf{A} \\in \\mathbb{R}^{L \\times K} \\ ; \\ \\mathbf{x} \\in \\mathbb{R}^K \\ ; \\ \\mathbf{b} \\in \\mathbb{R}^L  \\ ; \\ \\mathbf{y} \\in \\mathbb{R}^L\n",
    "$$\n",
    "\n",
    "If we apply the data vectors $\\mathbf{x}_j : \\ j = 1, \\ldots,\\ N$ to this matrix equation we get transformed data vectors $\\mathbf{y}_j : \\ j = 1, \\ldots,\\ N$\n",
    "\n",
    "We want to compute the expection $E(\\mathbf{y}$  :\n",
    "\n",
    "$$\\begin{gather}\n",
    "E(\\mathbf{y}) = \\frac{1}{N} \\sum_{j=1}^N \\mathbf{y}_j + \\mathbf{b} = \\left[\\begin{array}{c}\n",
    "\\frac{1}{N} \\sum_{j=1}^N y_{1,j} \\\\ \\vdots \\\\ \\frac{1}{N} \\sum_{j=1}^N y_{i,j} \\\\ \\vdots \\\\ \\frac{1}{N} \\sum_{j=1}^N y_{L,j}\n",
    "\\end{array}\\right] + \\mathbf{b}  \\\\\n",
    "\\ = \\left[\\begin{array}{c}\n",
    "\\frac{1}{N} \\sum_{j=1}^N \\sum_{k=1}^K a_{(1,\\ k)} \\cdot x_{(k,j)} \\\\ \\vdots \\\\ \\frac{1}{N} \\sum_{j=1}^N  \\\\ \\vdots \\\\ \\frac{1}{N} \\sum_{j=1}^N \n",
    "\\end{array}\\right] + \\mathbf{b} = \\left[\\begin{array}{c}\n",
    "\\sum_{k=1}^K a_{(1,\\ k)} \\cdot\\left(\\frac{1}{N} \\sum_{j=1}^N  x_{(k,j)}\\right) \\\\ \\vdots \\\\ \\frac{1}{N} \\sum_{j=1}^N  \\\\ \\vdots \\\\ \\frac{1}{N} \\sum_{j=1}^N \n",
    "\\end{array}\\right] + \\mathbf{b} \\\\\n",
    "\\ = \\left[\\begin{array}{c}\n",
    "\\sum_{k=1}^K a_{(1,\\ k)} \\cdot E(\\mathbf{x}) \\\\ \\vdots \\\\ \\sum_{k=1}^K a_{(i,\\ k)} \\cdot E(\\mathbf{x})  \\\\ \\vdots \\\\ \\sum_{k=1}^K a_{(L,\\ k)} \\cdot E(\\mathbf{x})  \n",
    "\\end{array}\\right] + \\mathbf{b} = \\mathbf{A} \\cdot E(\\mathbf{x}) + \\mathbf{b} \n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "Important here is the fact that compute the expectation vector $E(\\mathbf{y})$ there is no need to compute `N` transformed data vectors $\\mathbf{y}_j$. The expectation vector $E(\\mathbf{x})$ can be directly applied to the matrix equation. Thus quite a number of matrix/vector multiplication are saved.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4047ace5-ed51-43b5-9551-0543455a38fb",
   "metadata": {},
   "source": [
    "## Variance\n",
    "\n",
    "We examine again *data matrix* $\\mathbf{D} : \\in \\mathbb{R}^{N \\times K}$ with `N` measurements. Each measurement has `K` items. Thus each row of $\\mathbf{D}$ represents a single measurement of `K` items (eg.: temperature, time, voltage, speed, ...).\n",
    "\n",
    "The `j-th` measurement has `K` measured items. These items are arranged into a column vector denoted $\\mathbf{d}_j$.\n",
    "\n",
    "$$\n",
    "\\mathbf{d}_j = \\left[\\begin{array}{c}\n",
    "d_{1}[j]  \\\\ \\vdots \\\\ d_{k}[j] \\\\ \\vdots \\\\ d_{K}[j]\n",
    "\\end{array}\\right] = \\left[\\begin{array}{c}\n",
    "d_{1,\\ j} \\\\  \\vdots \\\\ d_{k\\ j} \\\\ \\vdots \\\\ d_{K\\ j}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "$d_{k}[j] = d_{k\\ j} $ denotes the `j-th` measurement of the `k-th` item.\n",
    "\n",
    "Now we define a vector $\\mathbf{w} : \\ \\in \\mathbb{R}^{K}$. This vector shall be used to compute a weighted addition of each measurement. For each measurement we compute the dot product $\\mathbf{w}^T \\mathbf{d}_j : \\ j=1, \\ldots , N$.\n",
    "\n",
    "For each measurement we get a scalar $s_j$:\n",
    "\n",
    "$$\n",
    "s_j = \\mathbf{w}^T \\mathbf{d}_j\n",
    "$$\n",
    "\n",
    "\n",
    "The average value of these `N` $s_j$ is denoted $E(s)$ and computed from\n",
    "\n",
    "$$\n",
    "E(s) = \\frac{1}{N} \\sum_{j=1}^N s_j = \\mathbf{w}^T  \\cdot \\underbrace{\\frac{1}{N} \\sum_{j=1}^N \\mathbf{d}_j}_{E(\\mathbf{d})} = \\mathbf{w}^T  \\cdot E(\\mathbf{d})\n",
    "$$\n",
    "\n",
    "$E(\\mathbf{d})$ denotes the element wise expectation of data items. Vector $E(\\mathbf{d}) : \\ \\in \\mathbb{R}^K$ can be expressed like this:\n",
    "\n",
    "$$\n",
    "E(\\mathbf{d}) = \\left[\\begin{array}{c}\n",
    "\\frac{1}{N} \\sum_{j=1}^N d_{1}[j] \\\\ \n",
    "\\vdots \\\\\n",
    "\\frac{1}{N} \\sum_{j=1}^N d_{k}[j] \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{1}{N} \\sum_{j=1}^N d_{K}[j]\n",
    "\\end{array}\\right] = \\left[\\begin{array}{c}\n",
    "\\frac{1}{N} \\sum_{j=1}^N d_{1,\\ j} \\\\ \n",
    "\\vdots \\\\\n",
    "\\frac{1}{N} \\sum_{j=1}^N d_{k,\\ j} \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{1}{N} \\sum_{j=1}^N d_{K,\\ j}\n",
    "\\end{array}\\right] = \\left[\\begin{array}{c}\n",
    "E(d_1) \\\\ \n",
    "\\vdots \\\\\n",
    "E(d_k) \\\\\n",
    "\\vdots \\\\\n",
    "E(d_K)\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "$E(d_k) = \\frac{1}{N} \\sum_{j=1}^N d_{k}[j] = \\frac{1}{N} \\sum_{j=1}^N d_{k,\\ j}$ is the mean value / expected value of the `k-th` measurement item.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0501a3-d1ea-469b-b453-abbb150911e5",
   "metadata": {},
   "source": [
    "## centered data set\n",
    "\n",
    "$$\n",
    "\\mathbf{c}_j = \\mathbf{d}_j - E(\\mathbf{d}) = \\left[\\begin{array}{c}\n",
    "d_{1}[j]  \\\\ \\vdots \\\\ d_{k}[j] \\\\ \\vdots \\\\ d_{K}[j]\n",
    "\\end{array}\\right] - \\left[\\begin{array}{c}\n",
    "E(d_1) \\\\ \n",
    "\\vdots \\\\\n",
    "E(d_k) \\\\\n",
    "\\vdots \\\\\n",
    "E(d_K)\n",
    "\\end{array}\\right] = \\left[\\begin{array}{c}\n",
    "d_{1,\\ j} \\\\  \\vdots \\\\ d_{k\\ j} \\\\ \\vdots \\\\ d_{K\\ j}\n",
    "\\end{array}\\right] - \\left[\\begin{array}{c}\n",
    "E(d_1) \\\\ \n",
    "\\vdots \\\\\n",
    "E(d_k) \\\\\n",
    "\\vdots \\\\\n",
    "E(d_K)\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "g_j = \\mathbf{w}^T \\mathbf{c}_j = \\mathbf{w}^T \\cdot \\left(\\mathbf{d}_j - E(\\mathbf{d}) \\right) = s_j - \\mathbf{w}^T \\cdot E(\\mathbf{d})\n",
    "$$\n",
    "\n",
    "The squared value $g^2_j$\n",
    "\n",
    "$$\n",
    "g^2_j = \\left(\\mathbf{w}^T \\mathbf{c}_j \\right)^2 = \\left(\\mathbf{w}^T \\mathbf{c}_j \\right) \\cdot \\left(\\mathbf{c}_j^T  \\mathbf{w} \\right) = \\mathbf{w}^T \\cdot \\left( \\mathbf{c}_j \\cdot \\mathbf{c}_j^T \\right) \\cdot  \\mathbf{w}\n",
    "$$\n",
    "\n",
    "Defining the square matrix $\\mathbf{C}_j : \\ \\in \\mathbb{R}^{K \\times K}$ by:\n",
    "\n",
    "$$\n",
    "\\mathbf{C}_j = \\mathbf{c}_j \\cdot \\mathbf{c}_j^T = \\left[\\begin{array}{ccccc}\n",
    "\\left(d_{1,\\ j} - E(d_1) \\right) \\cdot \\left(d_{1,\\ j} - E(d_1) \\right) & \\cdots & \\left(d_{1,\\ j} - E(d_1) \\right) \\cdot \\left(d_{k,\\ j} - E(d_k) \\right) & \\cdots & \\left(d_{1,\\ j} - E(d_1) \\right) \\cdot \\left(d_{K,\\ j} - E(d_K) \\right] \\\\\n",
    "\\vdots & \\vdots & \\ldots & \\vdots & \\vdots \\\\\n",
    "\\left(d_{k,\\ j} - E(d_k) \\right) \\cdot \\left(d_{1,\\ j} - E(d_1) \\right) & \\cdots & \\left(d_{k,\\ j} - E(d_k) \\right) \\cdot \\left(d_{k,\\ j} - E(d_k) \\right) & \\cdots & \\left(d_{k,\\ j} - E(d_k) \\right) \\cdot \\left(d_{K,\\ j} - E(d_K) \\right] \\\\\n",
    "\\vdots & \\vdots & \\ldots & \\vdots & \\vdots \\\\\n",
    "\\left(d_{K,\\ j} - E(d_K) \\right) \\cdot \\left(d_{1,\\ j} - E(d_1) \\right) & \\cdots & \\left(d_{K,\\ j} - E(d_K) \\right) \\cdot \\left(d_{k,\\ j} - E(d_k) \\right) & \\cdots & \\left(d_{K,\\ j} - E(d_K) \\right) \\cdot \\left(d_{K,\\ j} - E(d_K) \\right] \\\\\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "With the defintion of $\\mathbf{C}_j $ we are able to write $g^2_j$ as:\n",
    "\n",
    "\n",
    "$$\n",
    "g^2_j = \\mathbf{w}^T \\cdot \\mathbf{C}_j \\cdot  \\mathbf{w}\n",
    "$$\n",
    "\n",
    "And the expectation as \n",
    "\n",
    "$$\n",
    "E(g^2) = \\mathbf{w}^T \\cdot \\left( \\frac{1}{N} \\sum_{j=1}^N \\mathbf{C}_j \\right) \\cdot  \\mathbf{w}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{C} = \\frac{1}{N} \\sum_{j=1}^N \\mathbf{C}_j\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{C} = \\frac{1}{N} \\sum_{j=1}^N \\mathbf{c}_j \\cdot \\mathbf{c}_j^T = \\left[\\begin{array}{ccccc}\n",
    "\\frac{1}{N} \\sum_{j=1}^N \\left(d_{1,\\ j} - E(d_1) \\right) \\cdot \\left(d_{1,\\ j} - E(d_1) \\right) & \\cdots & \\frac{1}{N} \\sum_{j=1}^N\\left(d_{1,\\ j} - E(d_1) \\right) \\cdot \\left(d_{k,\\ j} - E(d_k) \\right) & \\cdots & \\frac{1}{N} \\sum_{j=1}^N \\left(d_{1,\\ j} - E(d_1) \\right) \\cdot \\left(d_{K,\\ j} - E(d_K) \\right] \\\\\n",
    "\\vdots & \\vdots & \\ldots & \\vdots & \\vdots \\\\\n",
    "\\frac{1}{N} \\sum_{j=1}^N \\left(d_{k,\\ j} - E(d_k) \\right) \\cdot \\left(d_{1,\\ j} - E(d_1) \\right) & \\cdots & \\frac{1}{N} \\sum_{j=1}^N \\left(d_{k,\\ j} - E(d_k) \\right) \\cdot \\left(d_{k,\\ j} - E(d_k) \\right) & \\cdots & \\frac{1}{N} \\sum_{j=1}^N \\left(d_{k,\\ j} - E(d_k) \\right) \\cdot \\left(d_{K,\\ j} - E(d_K) \\right] \\\\\n",
    "\\vdots & \\vdots & \\ldots & \\vdots & \\vdots \\\\\n",
    "\\frac{1}{N} \\sum_{j=1}^N \\left(d_{K,\\ j} - E(d_K) \\right) \\cdot \\left(d_{1,\\ j} - E(d_1) \\right) & \\cdots & \\frac{1}{N} \\sum_{j=1}^N \\left(d_{K,\\ j} - E(d_K) \\right) \\cdot \\left(d_{k,\\ j} - E(d_k) \\right) & \\cdots & \\frac{1}{N} \\sum_{j=1}^N \\left(d_{K,\\ j} - E(d_K) \\right) \\cdot \\left(d_{K,\\ j} - E(d_K) \\right] \\\\\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "The elements of matrix $\\mathbf{C} : \\in \\mathbb{R}^{K \\times K}$ are denoted $v_{l, \\ m} : \\ l = 1, \\ldots, K ; \\ m = 1, \\ldots, K $.\n",
    "\n",
    "$$\n",
    "v_{l, \\ m} = \\frac{1}{N} \\sum_{j=1}^N \\left(d_{l,\\ j} - E(d_l) \\right) \\cdot \\left(d_{m,\\ j} - E(d_m) \\right)\n",
    "$$\n",
    "\n",
    "**case: $l = m$**  (diagonal elements of $\\mathbf{C}$)\n",
    "\n",
    "$$\\begin{gather}\n",
    "v_{l, \\ l} = \\frac{1}{N} \\sum_{j=1}^N \\left(d_{l,\\ j} - E(d_l) \\right)^2 \\\\\n",
    "\\ = \\frac{1}{N} \\sum_{j=1}^N d_{l,\\ j}^2 - E(d_l)^2 = E(d_l^2) - E(d_l)^2 = Variance(d_l) = Var(d_l)\n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "**case: $l \\neq m$** (off-diagonal elements of $\\mathbf{C}$)\n",
    "\n",
    "$$\\begin{gather}\n",
    "v_{l, \\ m} = \\frac{1}{N} \\sum_{j=1}^N d_{l,\\ j} \\cdot d_{m,\\ j} - E(d_m) \\cdot \\frac{1}{N} \\sum_{j=1}^N d_{l,\\ j} - E(d_l) \\cdot \\frac{1}{N} \\sum_{j=1}^N d_{m,\\ j} + E(d_l) \\cdot E(d_m) \\\\\n",
    "\\ = E(d_{l,\\ j} \\cdot d_{m,\\ j}) - 2 \\cdot E(d_l) \\cdot E(d_m) + E(d_l) \\cdot E(d_m) \\\\\n",
    "\\ = E(d_l \\cdot d_m) - E(d_l) \\cdot E(d_m) = Covariance(d_l, d_m) = Cov(d_l, d_m)\n",
    "\\end{gather}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d0c14c-668c-4c91-a47f-536378e912da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3333ebc6-2d62-4aad-9b9a-ab46dfc440d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
