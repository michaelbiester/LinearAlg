{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bcab729-9af1-4a5b-a3ec-cc10ab3ff664",
   "metadata": {},
   "source": [
    "# Singular Value Decomposition\n",
    "\n",
    "Sources:\n",
    "\n",
    "  1) `Linear Algebra : Theory, Intuition, Code` author: Mike X Cohen, publisher: sincXpress\n",
    "\n",
    "  2)  `Matrix Methods for Computational Modeling and Data Analytics` author: Mark Embree, Virginia Tech\n",
    "\n",
    "This notebook has been setup to understand how singular value decomposition works. The content is mainly an adaption of the chapter 16 of `Linear Algebra : Theory, Intuition, Code` and of chapter 5 `The singular value decomposition` of `Matrix Methods for Computational Modeling and Data Analytics`. I have used mostly `Matrix Methods for Computational Modeling and Data Analytics` because to me it seems more accessible than `Linear Algebra : Theory, Intuition, Code` .\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8d617bb-6084-46c1-a2e2-3acfe6ee6a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some imports for numerical experiments\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca58188-162f-4a75-8848-9126ea7866e1",
   "metadata": {},
   "source": [
    "## Derivation of Singular Value Decomposition\n",
    "\n",
    "mainly from `Matrix Methods for Computational Modeling and Data Analytics` \n",
    "\n",
    "All columns of matrix $\\mathbf{A} \\in \\mathbb{R}^{m \\times n} \\ : \\ m \\ge n$ shall be linearly independent. Thus the rank of the matrix is as large as possible.\n",
    "\n",
    "From $\\mathbf{A}$ a square matrix $\\mathbf{A}^T \\cdot \\mathbf{A} \\in \\mathbb{R}^{m \\times m}$ is constructed. This matrix is symmetric and it is also *positive-definite* $\\mathbf{x}^T \\cdot \\mathbf{A}^T \\cdot \\mathbf{A} \\cdot \\mathbf{x} \\ge 0$\n",
    "\n",
    "An implication of $\\mathbf{A}^T \\cdot \\mathbf{A}$ being `positive-definite` is that its eigenvalues are positive.\n",
    "\n",
    "We can therefore find pairs of eigenvalues/eigenvectors $\\lambda_j,\\ \\mathbf{v}_j \\ : \\ 1 \\le j le n$. Also the ordering of these pair is arbitrary we assume descending ordering of eigenvalues such as $\\lambda_1 \\ge \\lambda_2 \\ge \\ldots \\ge \\lambda_n \\gt 0$.\n",
    "\n",
    "Eigenvectors $\\mathbf{v}_j$ have unit length $||\\mathbf{v}_j|| = 1$. Moreover they are mutually orthonormal $\\mathbf{v}_j^T \\cdot \\mathbf{v}_k = 0 \\ for \\ j \\neq k$.\n",
    "\n",
    "Since we have \n",
    "\n",
    "$$\\begin{gather}\n",
    "\\mathbf{v}_j^T \\cdot \\mathbf{A}^T \\cdot \\mathbf{A} \\cdot \\mathbf{v}_j = \\left(\\mathbf{A} \\cdot \\mathbf{v}_j\\right)^T \\cdot \\left(\\mathbf{A} \\cdot \\mathbf{v}_j \\right) = \\lambda_j \\cdot \\mathbf{v}_j^T \\cdot \\mathbf{v}_j = \\lambda_j = ||\\mathbf{A} \\cdot \\mathbf{v}_j ||^2 \\\\\n",
    "\\to \\\\\n",
    "\\sqrt{\\lambda_j} = ||\\mathbf{A} \\cdot \\mathbf{v}_j ||\n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "The positive square root of eigenvalue $\\lambda_j$ is defined as *singular value* $\\sigma_j$.\n",
    "\n",
    "$$\n",
    "\\sigma_j = \\sqrt{\\lambda_j} = ||\\mathbf{A} \\cdot \\mathbf{v}_j ||\n",
    "$$\n",
    "\n",
    "and because we arranged eigenvalues in decreasing order we get $\\sigma_1 \\ge \\sigma_2 \\ge  \\ldots \\ge \\sigma_n \\gt 0$ (singular values of $\\mathbf{A}$).\n",
    "\n",
    "Now we define new vectors $\\mathbf{u}_j = \\mathbf{A} \\cdot \\frac{\\mathbf{v}_j}{\\sigma_j}$.\n",
    "\n",
    "The vectors have *unit length* and they are *mutually orthonormal*. These properties are derived here:\n",
    "\n",
    "The unit length property follows directly from\n",
    "\n",
    "$$\n",
    "||\\mathbf{u}_j||^2 = \\left(\\mathbf{A} \\cdot \\frac{\\mathbf{v}_j}{\\sigma_j}\\right)^T \\cdot \\mathbf{A} \\cdot \\frac{\\mathbf{v}_j}{\\sigma_j} = \\frac{1}{\\sigma_j^2} \\cdot ||\\mathbf{A} \\cdot \\mathbf{v}_j||^2 = 1\n",
    "$$\n",
    "\n",
    "Orthogonality is proved like this:\n",
    "\n",
    "$$\n",
    "\\mathbf{u}_j^T \\cdot \\mathbf{u}_k = \\left(\\mathbf{A} \\cdot \\frac{\\mathbf{v}_j}{\\sigma_j}\\right)^T \\cdot \\mathbf{A} \\cdot \\frac{\\mathbf{v}_k}{\\sigma_k} = \\frac{1}{\\sigma_j \\cdot \\sigma_k} \\cdot \\mathbf{v}_j^T \\cdot \\mathbf{A}^T \\mathbf{A} \\cdot \\mathbf{v}_k = \\frac{\\lambda_k}{\\sigma_j \\cdot \\sigma_k} \\cdot \\underbrace{\\mathbf{v}_j^T \\cdot \\mathbf{v}_k}_{0 \\ : \\ j \\neq k}\n",
    "$$\n",
    "\n",
    "**Summary**\n",
    "\n",
    "$$\n",
    "\\sigma_j \\cdot \\mathbf{u}_j = \\mathbf{A} \\cdot \\mathbf{v}_j\n",
    "$$\n",
    "\n",
    "Arranging the column vectors of both sides of the equation yields a matrix equation:\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{cccc}\n",
    "\\vert & \\vert & & \\vert \\\\\n",
    "\\mathbf{A} \\mathbf{v}_1 & \\mathbf{A} \\mathbf{v}_2 & \\cdots & \\mathbf{A} \\mathbf{v}_n \\\\\n",
    "\\vert & \\vert & & \\vert\n",
    "\\end{array}\\right] = \\left[\\begin{array}{cccc}\n",
    "\\vert & \\vert & & \\vert \\\\\n",
    "\\sigma_1 \\mathbf{u}_1 & \\sigma_2 \\mathbf{u}_2 & \\cdots & \\sigma_n \\mathbf{u}_n \\\\\n",
    "\\vert & \\vert & & \\vert \\\\\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Each side of the matrix equation can be further decomposed into a product of matrices:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\cdot \\underbrace{\\left[\\begin{array}{cccc}\n",
    "\\vert & \\vert & & \\vert \\\\\n",
    "\\mathbf{v}_1 & \\mathbf{v}_2 & \\cdots & \\mathbf{v}_n \\\\\n",
    "\\vert & \\vert & & \\vert\n",
    "\\end{array}\\right]}_{\\mathbf{V}} = \\underbrace{\\left[\\begin{array}{cccc}\n",
    "\\vert & \\vert & & \\vert \\\\\n",
    "\\mathbf{u}_1 & \\mathbf{u}_2 & \\cdots & \\mathbf{u}_n \\\\\n",
    "\\vert & \\vert & & \\vert \\\\\n",
    "\\end{array}\\right]}_{\\mathbf{U}} \\cdot \\underbrace{\\left[\\begin{array}{cccc}\n",
    "\\sigma_1 & & & \\\\\n",
    " & \\sigma_2 & & \\\\\n",
    " & & \\ddots & \\\\\n",
    "  & & & \\sigma_n\n",
    "\\end{array}\\right]}_{\\mathbf{\\Sigma}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\cdot \\mathbf{V} = \\mathbf{U} \\cdot \\mathbf{\\Sigma}\n",
    "$$\n",
    "\n",
    "$\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$, $\\mathbf{V} \\in \\mathbb{R}^{n \\times n}$, $\\mathbf{U} \\in \\mathbb{R}^{m \\times n}$ and $\\mathbf{\\Sigma} \\in \\mathbb{R}^{n \\times n}$\n",
    "\n",
    "Since $\\mathbf{V}^T \\mathbf{V} = \\mathbf{I}$ we have $\\mathbf{V}^{-1} = \\mathbf{V}^T$. Therefore $\\mathbf{V} \\cdot \\mathbf{V}^T =  \\mathbf{V} \\cdot \\mathbf{V}^{-1} = \\mathbf{I}$.\n",
    "\n",
    "\n",
    "$$\\begin{gather}\n",
    "\\mathbf{A} \\cdot \\mathbf{V} \\cdot \\mathbf{V}^T = \\mathbf{U} \\cdot \\mathbf{\\Sigma} \\cdot \\mathbf{V}^T \\\\\n",
    "\\to \\\\\n",
    "\\mathbf{A} = \\mathbf{U} \\cdot \\mathbf{\\Sigma} \\cdot \\mathbf{V}^T \n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37983ea1-49e2-4833-8957-b45b26b6886d",
   "metadata": {},
   "source": [
    "### A worked example\n",
    "\n",
    "Given a $3 \\times 2$ matrix $\\mathbf{A}$.\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\left[\\begin{array}{cc}\n",
    "1 & 1 \\\\\n",
    "0 & 0 \\\\\n",
    "\\sqrt{2} & -\\sqrt{2}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^T \\mathbf{A} = \\left[\\begin{array}{cc}\n",
    "3 & -1  \\\\\n",
    "-1 & 3\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "\n",
    "Eigenvalues of $\\mathbf{A}^T \\mathbf{A}$ are computed from the characteristic polynomial.\n",
    "\n",
    "$$\n",
    "det \\left(\\begin{array}{cc}\n",
    "3 -\\lambda & -1  \\\\\n",
    "-1 & 3-\\lambda\n",
    "\\end{array}\\right) = \\left(9 - 6 \\cdot \\lambda + \\lambda^2 - 1 \\right) = \\lambda^2 - 6 \\cdot \\lambda + 8\n",
    "$$\n",
    "\n",
    "Eigenvalues are: $\\lambda_1 = 4$ and $\\lambda_2 = 2$. The corresponding eigenvectors $\\mathbf{v}_1$ and $\\mathbf{v}_2$ are computed from:\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{cc}\n",
    "3-4 & -1  \\\\\n",
    "-1 & 3-4\n",
    "\\end{array}\\right] = \\left[\\begin{array}{cc}\n",
    "-1 & -1  \\\\\n",
    "-1 & -1\n",
    "\\end{array}\\right] = \n",
    "\\left[\\begin{array}{c}\n",
    "0 \\\\\n",
    "0 \n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_1 = \\left[\\begin{array}{c}\n",
    "1/\\sqrt{2} \\\\\n",
    "-1/\\sqrt{2}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{cc}\n",
    "3-2 & -1  \\\\\n",
    "-1 & 3-2\n",
    "\\end{array}\\right] = \\left[\\begin{array}{cc}\n",
    "1 & -1  \\\\\n",
    "-1 & 1\n",
    "\\end{array}\\right] = \n",
    "\\left[\\begin{array}{c}\n",
    "0 \\\\\n",
    "0 \n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_2 = \\left[\\begin{array}{c}\n",
    "1/\\sqrt{2} \\\\\n",
    "1/\\sqrt{2}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Accordingly singular values are: $\\sigma_1 = \\sqrt{\\lambda_1} = 2$ and $\\sigma_2 = \\sqrt{\\lambda_2} = \\sqrt{2}$.\n",
    "\n",
    "In the next step vectors $\\mathbf{u}_1$ and $\\mathbf{u}_2$ are computed.\n",
    "\n",
    "$$\n",
    "\\mathbf{u}_1 =  \\mathbf{A} \\cdot \\frac{\\mathbf{v}_1}{\\sigma_1} = \\frac{1}{2} \\cdot \\left[\\begin{array}{cc}\n",
    "1 & 1 \\\\\n",
    "0 & 0 \\\\\n",
    "\\sqrt{2} & -\\sqrt{2}\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{c}\n",
    "1/\\sqrt{2} \\\\\n",
    "-1/\\sqrt{2}\n",
    "\\end{array}\\right] = \\left[\\begin{array}{c}\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "1\n",
    "\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{u}_2 =  \\mathbf{A} \\cdot \\frac{\\mathbf{v}_2}{\\sigma_2} = \\frac{1}{\\sqrt{2}} \\cdot \\left[\\begin{array}{cc}\n",
    "1 & 1 \\\\\n",
    "0 & 0 \\\\\n",
    "\\sqrt{2} & -\\sqrt{2}\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{c}\n",
    "1/\\sqrt{2} \\\\\n",
    "1/\\sqrt{2}\n",
    "\\end{array}\\right] = \\left[\\begin{array}{c}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "0\n",
    "\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "\n",
    "We are now able to write the matrix decomposition:\n",
    "\n",
    "$$\n",
    "\\underbrace{\\left[\\begin{array}{cc}\n",
    "1 & 1 \\\\\n",
    "0 & 0 \\\\\n",
    "\\sqrt{2} & -\\sqrt{2}\n",
    "\\end{array}\\right]}_{\\mathbf{A}} = \\underbrace{\\left[\\begin{array}{cc}\n",
    "0 & 1 \\\\\n",
    "0 & 0 \\\\\n",
    "1 & 0 \n",
    "\\end{array}\\right]}_{\\mathbf{U}} \\cdot \\underbrace{\\left[\\begin{array}{cc}\n",
    "2 & 0 \\\\\n",
    "0 & \\sqrt{2}\n",
    "\\end{array}\\right]}_{\\mathbf{\\Sigma}} \\cdot \\underbrace{\\left[\\begin{array}{cc}\n",
    "1/\\sqrt{2} & -1/\\sqrt{2}\\\\\n",
    "1/\\sqrt{2} & 1/\\sqrt{2}\n",
    "\\end{array}\\right]}_{\\mathbf{\\mathbf{V}}^T}\n",
    "$$\n",
    "\n",
    "Below is a numerical example using `Numpy`.\n",
    "\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.linalg.svd.html\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d42e65-4138-4151-ae4b-c23cba474841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amat         :\n",
      "[[ 1.          1.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 1.41421356 -1.41421356]]\n",
      "\n",
      "Umat         :\n",
      "[[ 4.01572963e-17 -1.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [-1.00000000e+00 -1.79477306e-16]]\n",
      "\n",
      "SingularVals :\n",
      "[2.         1.41421356]\n",
      "\n",
      "Vtmat        :\n",
      "[[-0.70710678  0.70710678]\n",
      " [-0.70710678 -0.70710678]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# numerical example\n",
    "Amat = np.array([[1,1], [0,0], [math.sqrt(2), -math.sqrt(2)]])\n",
    "\n",
    "Umat, SingularVals, Vtmat = np.linalg.svd(Amat, full_matrices=False)\n",
    "\n",
    "print(f\"Amat         :\\n{Amat}\\n\")\n",
    "print(f\"Umat         :\\n{Umat}\\n\")\n",
    "print(f\"SingularVals :\\n{SingularVals}\\n\")\n",
    "print(f\"Vtmat        :\\n{Vtmat}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edff5e77-28fd-4b3b-8da5-b2a88d260862",
   "metadata": {},
   "source": [
    "\n",
    "**Note**\n",
    "\n",
    "`Umat` is equivalent to $-\\mathbf{U}$ and `Vtmat` is equivalent to $-\\mathbf{V}^T$. So these signs cancel each other.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c250af-72fe-4ac1-8825-fe9d4a3b6a1b",
   "metadata": {},
   "source": [
    "## Another Way to formulate the `SVD`\n",
    "\n",
    "Again a matrix $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ with linearly independent columns is assumed.\n",
    "\n",
    "The singular value decomposition has been found as:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\mathbf{U} \\cdot \\mathbf{\\Sigma} \\cdot \\mathbf{V}^T \n",
    "$$\n",
    "\n",
    "With the matrix product $\\mathbf{U} \\cdot \\mathbf{\\Sigma}$ expressed as:\n",
    "\n",
    "$$\n",
    "\\mathbf{U} \\cdot \\mathbf{\\Sigma} = \\left[\\begin{array}{cccc}\n",
    "\\vert & \\vert & & \\vert \\\\\n",
    "\\sigma_1 \\mathbf{u}_1 & \\sigma_2 \\mathbf{u}_2 & \\cdots & \\sigma_n \\mathbf{u}_n \\\\\n",
    "\\vert & \\vert & & \\vert\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "matrix $\\mathbf{A}$ is written like this:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\left[\\begin{array}{cccc}\n",
    "\\vert & \\vert & & \\vert \\\\\n",
    "\\sigma_1 \\mathbf{u}_1 & \\sigma_2 \\mathbf{u}_2 & \\cdots & \\sigma_n \\mathbf{u}_n \\\\\n",
    "\\vert & \\vert & & \\vert\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{ccc}\n",
    "- & \\mathbf{v}_1^T & - \\\\\n",
    "- & \\mathbf{v}_2^T & - \\\\\n",
    "  & \\cdots & \\\\\n",
    "- & \\mathbf{v}_n^T & - \n",
    "\\end{array}\\right] = \\sum_{j=1}^n \\sigma_1 \\cdot \\mathbf{u}_j \\cdot \\mathbf{v}_j^T\n",
    "$$\n",
    "\n",
    "Therefore the `SVD` of $\\mathbf{A}$ may be expressed as the sum of `n` submatrices $\\sigma_1 \\cdot \\mathbf{u}_j \\cdot \\mathbf{v}_j$.\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\sum_{j=1}^n \\sigma_1 \\cdot \\mathbf{u}_j \\cdot \\mathbf{v}_j^T \n",
    "$$\n",
    "\n",
    "To illustrate this equation we use again \n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\left[\\begin{array}{cc}\n",
    "1 & 1 \\\\\n",
    "0 & 0 \\\\\n",
    "\\sqrt{2} & -\\sqrt{2}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "and decompose it into\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\sum_{j=1}^{2} \\sigma_j \\cdot \\mathbf{u}_j \\cdot \\mathbf{v}_j^T  = \\sigma_1 \\cdot \\mathbf{u}_1 \\cdot \\mathbf{v}_1^T + \\sigma_2 \\cdot \\mathbf{u}_2 \\cdot \\mathbf{v}_2^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\left[\\begin{array}{cc}\n",
    "1 & 1 \\\\\n",
    "0 & 0 \\\\\n",
    "\\sqrt{2} & -\\sqrt{2}\n",
    "\\end{array}\\right] = \n",
    "2 \\cdot \\left[\\begin{array}{c}\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "1\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{cc}\n",
    "1/\\sqrt{2} & -1/\\sqrt{2}\n",
    "\\end{array}\\right] + \\sqrt{2} \\cdot \\left[\\begin{array}{c}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "0\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{cc}\n",
    "1/\\sqrt{2} & 1/\\sqrt{2}\n",
    "\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\left[\\begin{array}{cc}\n",
    "0 & 0 \\\\\n",
    "0 & 0 \\\\\n",
    "\\sqrt{2} & -\\sqrt{2}\n",
    "\\end{array}\\right] + \\left[\\begin{array}{cc}\n",
    "1 & 1 \\\\\n",
    "0 & 0 \\\\\n",
    "0 & 0\n",
    "\\end{array}\\right] = \\left[\\begin{array}{cc}\n",
    "1 & 1 \\\\\n",
    "0 & 0 \\\\\n",
    "\\sqrt{2} & -\\sqrt{2}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fe303d-cd99-4951-841f-b1574095ca99",
   "metadata": {},
   "source": [
    "### A simple application\n",
    "\n",
    "The `SVD` shall be used to solve the matrix equation $\\mathbf{A} \\cdot \\mathbf{x} = \\mathbf{b}$. Assumption for matrix $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$:  $\\mathbf{A}$ is invertible. So its inverse $\\mathbf{A}^{-1}$ exists.\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\mathbf{U} \\cdot \\mathbf{\\Sigma} \\cdot \\mathbf{V}^T = \\sum_{j=1}^n \\sigma_1 \\cdot \\mathbf{u}_j \\cdot \\mathbf{v}_j^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\cdot \\mathbf{x} = \\mathbf{U} \\cdot \\mathbf{\\Sigma} \\cdot \\mathbf{V}^T \\cdot \\mathbf{x} = \\sum_{j=1}^n \\sigma_1 \\cdot \\mathbf{u}_j \\cdot \\left(\\mathbf{v}_j^T \\cdot \\mathbf{x} \\right) = \\mathbf{b}\n",
    "$$\n",
    "\n",
    "Using $\\mathbf{U}^T \\cdot \\mathbf{U} = \\mathbf{I}$ we obtain:\n",
    "\n",
    "$$\\begin{gather}\n",
    "\\mathbf{U}^T \\cdot \\mathbf{U} \\cdot \\mathbf{\\Sigma} \\cdot \\mathbf{V}^T \\cdot \\mathbf{x} = \\mathbf{U}^T \\cdot \\mathbf{b} \\\\\n",
    "\\mathbf{\\Sigma} \\cdot \\mathbf{V}^T \\cdot \\mathbf{x} = \\mathbf{U}^T \\cdot \\mathbf{b}\n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "With the inverse matrix \n",
    "\n",
    "$$\n",
    "\\mathbf{\\Sigma}^{-1} = \\left[\\begin{array}{cccc}\n",
    "1/\\sigma_1 &  &  & \\\\\n",
    "& 1/\\sigma_2 & & \\\\\n",
    "& & \\ddots & \\\\\n",
    "& & & 1/\\sigma_n\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "we have \n",
    "\n",
    "$$\\begin{gather}\n",
    "\\mathbf{\\Sigma}^{-1} \\cdot \\mathbf{\\Sigma} \\cdot \\mathbf{V}^T \\cdot \\mathbf{x} = \\mathbf{\\Sigma}^{-1} \\cdot \\mathbf{U}^T \\cdot \\mathbf{b} \\\\\n",
    "\\mathbf{V}^T \\cdot \\mathbf{x} = \\mathbf{\\Sigma}^{-1} \\cdot \\mathbf{U}^T \\cdot \\mathbf{b} \\\\\n",
    "\\mathbf{V} \\cdot \\mathbf{V}^T \\cdot \\mathbf{x} = \\mathbf{V} \\cdot \\mathbf{\\Sigma}^{-1} \\cdot \\mathbf{U}^T \\cdot \\mathbf{b} \\\\\n",
    "\\to \\\\\n",
    "\\mathbf{x} = \\mathbf{V} \\cdot \\mathbf{\\Sigma}^{-1} \\cdot \\mathbf{U}^T \\cdot \\mathbf{b}\n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "We conclude that\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^{-1} = \\mathbf{V} \\cdot \\mathbf{\\Sigma}^{-1} \\cdot \\mathbf{U}^T = \\sum_{j=1}^n \\frac{1}{\\sigma_j} \\mathbf{v}_j \\cdot \\mathbf{u}_j^T\n",
    "$$\n",
    "\n",
    "$$\\begin{gather}\n",
    "\\mathbf{x} = \\mathbf{A}^{-1} \\cdot \\mathbf{b} = \\sum_{j=1}^n \\frac{1}{\\sigma_j} \\mathbf{v}_j \\cdot \\left(\\mathbf{u}_j^T \\cdot \\mathbf{b}\\right) \\\\\n",
    "\\mathbf{x} = \\sum_{j=1}^n \\left(\\frac{\\mathbf{u}_j^T \\cdot \\mathbf{b}}{\\sigma_j}\\right) \\cdot \\mathbf{v}_j  \n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "We see that $\\mathbf{x}$ is the weighted addition of eigenvectors $\\mathbf{v}_1,\\ \\mathbf{v}_2,\\ldots,\\ \\mathbf{v}_n$ of symmetric matrix $\\mathbf{A}^T \\mathbf{A}$.\n",
    "\n",
    "The next section is about the `Full SVD`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3d329c-f479-4cd8-8356-01d7d428d4fb",
   "metadata": {},
   "source": [
    "## Full SVD \n",
    "\n",
    "Assumption are the same as for the reduced version of the `SVD`.\n",
    "\n",
    "1) $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ with $m \\ge n$.\n",
    "\n",
    "2) Again the `n` columns of the matrix shall be linearly independent.\n",
    "\n",
    "Contrary to the reduced version of the `SVD` where matrix $\\mathbf{U} \\in \\mathbb{R}^{m \\times n}$ has `n` orthonormal columns, we generate an `augmented `matrix $\\widetilde{\\mathbf{U}} \\in \\mathbb{R}^{m \\times m}$ by adding $m-n$ *extra* column vectors to the reduced matrix $\\mathbf{U}$. Finally all column vectors of $\\widetilde{\\mathbf{U}}$ are mutally orthonormal.\n",
    "\n",
    "**ToDo**\n",
    "\n",
    "The exact procedure to achieve these extra column vectors should be made more explicit. Here we just postulate that such augmentation is feasible.\n",
    "\n",
    "The orthonormal column vectors of the augmented matrix $\\widetilde{\\mathbf{U}}$ are denoted $\\mathbf{u}_1,\\ \\mathbf{u}_2,\\ \\ldots, \\mathbf{u}_n,\\ \\mathbf{u}_{n+1},\\ \\ldots ,\\ \\mathbf{u}_m$.\n",
    "\n",
    "$$\n",
    "\\widetilde{\\mathbf{U}} = \\left[\\begin{array}{cccccc}\n",
    "\\vert & & \\vert & \\vert & & \\vert \\\\\n",
    "\\mathbf{u}_1 & \\cdots & \\mathbf{u}_n & \\mathbf{u}_{n+1} & \\cdots & \\mathbf{u}_m \\\\\n",
    "\\vert & & \\vert & \\vert & & \\vert \n",
    "\\end{array}\\right] \\in \\mathbb{R}^{m \\times m}\n",
    "$$\n",
    "\n",
    "Since $\\widetilde{\\mathbf{U}}$ is square with `m` orthonormal columns we have:\n",
    "\n",
    "$$\n",
    "\\widetilde{\\mathbf{U}}^T \\widetilde{\\mathbf{U}} = \\mathbf{I}\n",
    "$$\n",
    "\n",
    "Moreover $\\widetilde{\\mathbf{U}}^{-1} = \\widetilde{\\mathbf{U}}^T $.\n",
    "\n",
    "The matrix $\\mathbf{\\Sigma} \\in \\mathbb{R}^{n \\times n}$ (already defined in the reduced `SVD`) is augmented to another matrix $\\widetilde{\\mathbf{\\Sigma}} \\in \\mathbb{R}^{m \\times n}$ by inserting $m-n$ zero values row vectors below the n`th row of $\\mathbf{\\Sigma}$.\n",
    "\n",
    "$$\n",
    "\\widetilde{\\mathbf{\\Sigma}} = \\left[\\begin{array}{c}\n",
    "\\mathbf{\\Sigma} \\\\\n",
    "\\underbrace{\\mathbf{0}}_{(m-n) \\times n}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Having augmented matrix $\\mathbf{U}$ by $m-n$ additional orthonormal columns to a matrix $\\widetilde{\\mathbf{U}}$ and extended matrix $\\mathbf{\\Sigma}$ by inserting $m-n$ zero rows to a matrix $\\widetilde{mathbf{\\Sigma}}$ we can now write the `Full SVD`.\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\widetilde{\\mathbf{U}} \\cdot \\widetilde{\\mathbf{\\Sigma}} \\cdot \\mathbf{V}^T\n",
    "$$\n",
    "\n",
    "As for the `reduced SVD` a numerical example shows some more details.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45be0247-4197-4ba3-a086-b6b37d19c65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amat                     :\n",
      "[[ 1.          1.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 1.41421356 -1.41421356]]\n",
      "\n",
      "Umat (augmented)         :\n",
      "[[ 4.01572963e-17 -1.00000000e+00 -1.81298661e-16]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.00000000e+00]\n",
      " [-1.00000000e+00 -1.79477306e-16  1.28197512e-16]]\n",
      "\n",
      "SingularVals (augmented) :\n",
      "[2.         1.41421356]\n",
      "\n",
      "Vtmat                    :\n",
      "[[-0.70710678  0.70710678]\n",
      " [-0.70710678 -0.70710678]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# numerical example\n",
    "Amat = np.array([[1,1], [0,0], [math.sqrt(2), -math.sqrt(2)]])\n",
    "\n",
    "Umat, SingularVals, Vtmat = np.linalg.svd(Amat, full_matrices=True)\n",
    "\n",
    "print(f\"Amat                     :\\n{Amat}\\n\")\n",
    "print(f\"Umat (augmented)         :\\n{Umat}\\n\")\n",
    "print(f\"SingularVals (augmented) :\\n{SingularVals}\\n\")\n",
    "print(f\"Vtmat                    :\\n{Vtmat}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9586dff2-e12b-487f-90b3-2ec5be337511",
   "metadata": {},
   "source": [
    "## Review (so far)\n",
    "\n",
    "We have so far dealt with two representations of the `SVD`:\n",
    "\n",
    "1) the `reduced SVD`\n",
    "\n",
    "2) the `full SVD`\n",
    "\n",
    "But for both cases we have made the <ins>same assumption</ins> regarding matrix $\\mathbf{A}$: The $m \\times n : m \\ge n$ matrix has full columns rank. $rank(\\mathbf{A}) = n$.\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66843bef-2d0c-445d-9d8b-49e91756be6b",
   "metadata": {},
   "source": [
    "## `Reduced SVD` : General case $m \\ge n$\n",
    "\n",
    "Now we consider a more general case:\n",
    "\n",
    "1) $m \\ge n$\n",
    "\n",
    "2) the columns of $\\mathbf{A}$ need to be all linearly independent.\n",
    "\n",
    "If there a linearly dependent columns of $\\mathbf{A}$ there exist some vector $\\mathbf{v} \\in \\mathbb{R}^n$ for which we have:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\cdot \\mathbf{v} = \\mathbf{0} \\ : \\ \\mathbf{v}\\neq \\mathbf{0} \n",
    "$$\n",
    "\n",
    "Multiplying this equation from the left by $\\mathbf{A}^T$ yields:\n",
    "\n",
    "$$\\begin{gather}\n",
    "\\mathbf{A}^T \\cdot \\mathbf{A} \\cdot \\mathbf{v} = \\mathbf{0} \\\\ \n",
    "\\mathbf{A}^T \\cdot \\mathbf{A} \\cdot \\mathbf{v} = 0 \\cdot \\mathbf{v}\n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "Vector $\\mathbf{v}$ is therefore an eigenvector of $\\mathbf{A}^T \\cdot \\mathbf{A}$ with eigenvalue $\\lambda = 0$. \n",
    "\n",
    "All vectors $\\mathbf{v}$ which satisfy $\\mathbf{A} \\cdot \\mathbf{v} = \\mathbf{0}$ are then eigenvectors with eigenvalue `0`.\n",
    "\n",
    "There a $r :\\ 0 \\le r \\le n$ non-zero eigenvalues $\\lambda_1 \\ge \\lambda_2 \\ge \\cdots \\ge \\lambda_r \\gt 0$. And there are $n-r$ zero eigenvalues $\\lambda_{r+1} = \\cdots =\\lambda_n = 0$.\n",
    "\n",
    "To these eigenvalues belong eigenvectors $\\mathbf{v}_1, \\mathbf{v}_2,\\ \\cdots ,\\mathbf{v}_n$.\n",
    "\n",
    "**Without Proof**\n",
    "\n",
    "1) Eigenvectors $\\mathbf{v}_{r+1}, \\ \\cdots ,\\mathbf{v}_n$ form a basis of the null space $R(\\mathbf{A})$. The basis vectors are orthonormal (proof required)\n",
    "\n",
    "2) Moreover $\\mathbf{v}_{r+1}, \\ \\cdots ,\\mathbf{v}_n$ are orthonormal to $\\mathbf{v}_1, \\ \\cdots ,\\mathbf{v}_r$ (proof required)\n",
    "\n",
    "Building the expression for the SVD proceeds in similar steps as before ..\n",
    "\n",
    "Define `singular values` $\\mathbf{\\sigma_j}$:\n",
    "\n",
    "$$\n",
    "\\mathbf{\\sigma_j} = \\sqrt{\\left(\\mathbf{A} \\cdot \\mathbf{v} \\right)^T \\cdot \\left(\\mathbf{A} \\cdot \\mathbf{v} \\right)} = ||\\mathbf{A} \\cdot \\mathbf{v}|| = \\sqrt{\\lambda_j} \\:\\ j=1,\\ldots, n\n",
    "$$\n",
    "\n",
    "Clearly $\\sigma_1 \\ge \\sigma_2 \\ge \\cdots \\ge \\sigma_r \\gt 0 $ and $\\sigma_{r+1} = \\cdots = \\sigma_n = 0 $\n",
    "\n",
    "Define orthonormal vectors $\\mathbf{u}_j$\n",
    "\n",
    "$$\n",
    "\\mathbf{u}_j = \\frac{1}{\\sigma_j} \\mathbf{A} \\cdot \\mathbf{v} : \\ j=1, \\ldots, r\n",
    "$$\n",
    "\n",
    "Augment the set of vectors $\\mathbf{u}_1, \\cdots, \\mathbf{u}_r$ by vectors $\\mathbf{u}_{r+1}, \\cdots, \\mathbf{u}_n$. (provide steps to do this)\n",
    "\n",
    "Due to its definition we also have:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\cdot \\mathbf{v}_j = \\sigma_j \\cdot \\mathbf{u}_j : j=1, \\ldots,\\ n\n",
    "$$\n",
    "\n",
    "And since $\\mathbf{A} \\cdot \\mathbf{v}_j = \\mathbf{0} : j = r+1,\\ldots,\\ n$ also $\\mathbf{u}_j = \\mathbf{u}_j \\ :\\ j = r+1,\\ldots,\\ n$.\n",
    "\n",
    "Now with $\\mathbf{A} \\cdot \\mathbf{v}_j = \\sigma_j \\cdot \\mathbf{u}_j : j=1, \\ldots,\\ n$ everything is ready to formulate the `SVD`.\n",
    "\n",
    "\n",
    "$$\\begin{align}\n",
    "\\left[\\begin{array}{cccccc} \n",
    "\\vert & & \\vert & \\vert & & \\vert \\\\\n",
    "\\mathbf{A} \\cdot \\mathbf{v}_1 & \\cdots & \\mathbf{A} \\cdot \\mathbf{v}_r & \\mathbf{A} \\cdot \\mathbf{v}_{r+1} & \\cdots & \\mathbf{A} \\cdot \\mathbf{v}_n \\\\\n",
    "\\vert & & \\vert & \\vert & & \\vert \n",
    "\\end{array}\\right] = \\left[\\begin{array}{cccccc}\n",
    "\\vert & & \\vert & \\vert & & \\vert \\\\\n",
    "\\sigma_1 \\cdot \\mathbf{u}_1 & \\cdots & \\sigma_r \\cdot \\mathbf{u}_r & \\sigma_{r+1} \\cdot \\mathbf{u}_{r+1} & \\cdots & \\sigma_n \\cdot \\mathbf{u}_n \\\\\n",
    "\\vert & & \\vert & \\vert & & \\vert \\\\\n",
    "\\end{array}\\right] = \\left[\\begin{array}{cccccc}\n",
    "\\vert & & \\vert & \\vert & & \\vert \\\\\n",
    "\\sigma_1 \\cdot \\mathbf{u}_1 & \\cdots & \\sigma_r \\cdot \\mathbf{u}_r & \\mathbf{0} & \\cdots & \\mathbf{0} \\\\\n",
    "\\vert & & \\vert & \\vert & & \\vert \\\\\n",
    "\\end{array}\\right]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "As before the matrices on either side of the equation can be expressed as products of matrices:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\cdot \n",
    "\\left[\\begin{array}{cccccc} \n",
    "\\vert & & \\vert & \\vert & & \\vert \\\\\n",
    "\\mathbf{v}_1 & \\cdots & \\mathbf{v}_r & \\mathbf{v}_{r+1} & \\cdots & \\mathbf{v}_n \\\\\n",
    "\\vert & & \\vert & \\vert & & \\vert \n",
    "\\end{array}\\right] = \\left[\\begin{array}{ccc}\n",
    "\\vert & & \\vert \\\\\n",
    "\\mathbf{u}_1 & \\cdots & \\mathbf{u}_r \\\\\n",
    "\\vert & & \\vert \\\\\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{ccccccc}\n",
    "\\sigma_1 & &  & \\vert & 0 & \\cdots & 0 \\\\\n",
    " & \\ddots &  & \\vert & \\vdots & \\ddots & \\vdots \\\\\n",
    " & & \\sigma_r &  \\vert & 0 & \\cdots & 0\n",
    "\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "\n",
    "In the next step we define to matrices $\\mathbf{V}$  and $\\mathbf{V}_\\perp$ :\n",
    "\n",
    "$$\n",
    "\\mathbf{V} = \\left[\\begin{array}{ccc}\n",
    "\\vert & & \\vert \\\\\n",
    "\\mathbf{v}_1 & \\cdots & \\mathbf{v}_r \\\\\n",
    "\\vert & & \\vert \\\\\n",
    "\\end{array}\\right] \\ : \\ \\in \\mathbb{R}^{n \\times r} \\ \\ \\\n",
    "\\mathbf{V}_\\perp = \\left[\\begin{array}{ccc}\n",
    "\\vert & & \\vert \\\\\n",
    "\\mathbf{v}_{r+1} & \\cdots & \\mathbf{v}_n \\\\\n",
    "\\vert & & \\vert \\\\\n",
    "\\end{array}\\right] \\ : \\ \\in \\mathbb{R}^{n \\times (n-r)}\n",
    "$$\n",
    "\n",
    "These matrices are concatenated into a single matrix $\\widetilde{\\mathbf{V}} \\in \\mathbb{R}^{n \\times n}$.\n",
    "\n",
    "$$\n",
    "\\widetilde{\\mathbf{V}}  = \\left[\\begin{array}{cc}\n",
    "\\mathbf{V} & \\mathbf{V}_\\perp\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "All columns of $\\widetilde{\\mathbf{V}}$ are mutually orthonormal. Therefore \n",
    "\n",
    "$$\\begin{gather}\n",
    "\\widetilde{\\mathbf{V}}^T \\cdot \\widetilde{\\mathbf{V}} = \\widetilde{\\mathbf{V}} \\cdot \\widetilde{\\mathbf{V}}^T = \\mathbf{I} \\\\\n",
    "\\widetilde{\\mathbf{V}}^{-1} = \\widetilde{\\mathbf{V}}^T\n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "Similarly we define matrix $\\mathbf{U}$ as the concatenation of `r` column vectors $\\mathbf{u}_1,\\ \\ldots, \\ \\mathbf{u}_r$.\n",
    "\n",
    "$$\n",
    "\\mathbf{U} = \\left[\\begin{array}{ccc}\n",
    "\\vert & & \\vert \\\\\n",
    "\\mathbf{u}_1 & \\cdots & \\mathbf{u}_r \\\\\n",
    "\\vert & & \\vert \\\\\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "And the `r` singualar values are put into a diagonal matrix $\\mathbf{\\Sigma} \\in \\mathbf{R}^{n \\times n}$.\n",
    "\n",
    "$$\n",
    "\\mathbf{\\Sigma} = \\left[\\begin{array}{ccc}\n",
    "\\sigma_1 & &  \\\\\n",
    " & \\ddots & \\\\\n",
    " & & \\sigma_r \\\\\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "\n",
    "With these definitions we get \n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\cdot \\widetilde{\\mathbf{V}} = \\mathbf{U} \\cdot \\left[\\begin{array}{cc}\n",
    "\\mathbf{\\Sigma} & \\mathbf{0} \\\\\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Multiplying both sides of the equation from the right by $\\widetilde{\\mathbf{V}}^T$ we obtain:\n",
    "\n",
    "$$\\begin{gather}\n",
    "\\mathbf{A} \\cdot \\widetilde{\\mathbf{V}} \\widetilde{\\mathbf{V}}^T = \\mathbf{U} \\cdot \\left[\\begin{array}{cc}\n",
    "\\mathbf{\\Sigma} & \\mathbf{0} \\\\\n",
    "\\end{array}\\right] \\cdot \\widetilde{\\mathbf{V}}^T \\\\\n",
    "\\mathbf{A} = \\mathbf{U} \\cdot \\left[\\begin{array}{cc}\n",
    "\\mathbf{\\Sigma} & \\mathbf{0} \\\\\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{cc}\n",
    "\\mathbf{V} & \\mathbf{V}_\\perp\n",
    "\\end{array}\\right]^T \\\\\n",
    "\\mathbf{A} = \\mathbf{U} \\cdot \\left[\\begin{array}{cc}\n",
    "\\mathbf{\\Sigma} & \\mathbf{0} \\\\\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{c}\n",
    "\\mathbf{V}^T \\\\\n",
    "\\mathbf{V}_\\perp^T\n",
    "\\end{array}\\right] \\\\\n",
    "\\mathbf{A} = \\mathbf{U} \\cdot \n",
    "\\mathbf{\\Sigma} \\cdot \n",
    "\\mathbf{V}^T \n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "The last equation looks like the `reduced SVD` for the full rank case. However the dimension of the matrices involved have been changed.\n",
    "\n",
    "$\\mathbf{U} \\in \\mathbb{R}^{m \\times r}$, $\\mathbf{\\Sigma} \\in \\mathbb{R}^{r \\times r}$ and $\\mathbf{V} \\in \\mathbb{R}^{n \\times r}$.\n",
    "\n",
    "**Summary**\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\mathbf{U} \\cdot \n",
    "\\mathbf{\\Sigma} \\cdot \n",
    "\\mathbf{V}^T = \\underbrace{\\left[\\begin{array}{ccc}\n",
    "\\vert & & \\vert \\\\\n",
    "\\mathbf{u}_1 & \\cdots & \\mathbf{u}_r \\\\\n",
    "\\vert & & \\vert \\\\\n",
    "\\end{array}\\right]}_{m \\times r} \\cdot \\underbrace{\\left[\\begin{array}{ccc}\n",
    "\\sigma_1 & &  \\\\\n",
    " & \\ddots & \\\\\n",
    " & & \\sigma_r \\\\\n",
    "\\end{array}\\right]}_{r \\times r} \\cdot \\underbrace{\\left[\\begin{array}{ccc}\n",
    "- &  \\mathbf{v}_1^T & - \\\\\n",
    " & \\vdots & \\\\\n",
    "- & \\mathbf{v}_r^T & - \n",
    "\\end{array}\\right]}_{r \\times n} = \\sum_{j=1}^r \\sigma_j \\cdot \\mathbf{u}_j \\cdot \\mathbf{v}_j^T \n",
    "$$\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390b8ed1-d1e0-4597-bd99-616da6baabde",
   "metadata": {},
   "source": [
    "### The full SVD : General case $m \\ge n$\n",
    "\n",
    "As in the reduced SVD case we use \n",
    "\n",
    "$$\n",
    "\\mathbf{V} = \\left[\\begin{array}{ccc}\n",
    "\\vert & & \\vert \\\\\n",
    "\\mathbf{v}_1 & \\cdots & \\mathbf{v}_r \\\\\n",
    "\\vert & & \\vert \\\\\n",
    "\\end{array}\\right] \\ : \\ \\in \\mathbb{R}^{n \\times r} \\ \\ \\\n",
    "\\mathbf{V}_\\perp = \\left[\\begin{array}{ccc}\n",
    "\\vert & & \\vert \\\\\n",
    "\\mathbf{v}_{r+1} & \\cdots & \\mathbf{v}_n \\\\\n",
    "\\vert & & \\vert \\\\\n",
    "\\end{array}\\right] \\ : \\ \\in \\mathbb{R}^{n \\times (n-r)} \\ \\ \\\n",
    "\\widetilde{\\mathbf{V}}= \\left[\\begin{array}{cc}\n",
    "\\mathbf{V}  & \\mathbf{V}_\\perp\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "In a similar fashion we define a matrix $\\widetilde{\\mathbf{U}} \\in \\mathbb{R}^{m \\times m}$ which is constructed from thr concatenation of matrices $\\mathbf{U} \\in \\mathbb{R}^{m \\times r}$ and $\\mathbf{U}_\\perp \\in \\mathbb{R}^{m \\times (m-r)}$.\n",
    "\n",
    "$$\n",
    "\\mathbf{U} = \\left[\\begin{array}{ccc}\n",
    "\\vert & & \\vert \\\\\n",
    "\\mathbf{u}_1 & \\cdots & \\mathbf{u}_r \\\\\n",
    "\\vert & & \\vert \\\\\n",
    "\\end{array}\\right] \\ : \\ \\in \\mathbb{R}^{m \\times r} \\ \\ \\\n",
    "\\mathbf{U}_\\perp = \\left[\\begin{array}{ccc}\n",
    "\\vert & & \\vert \\\\\n",
    "\\mathbf{u}_{r+1} & \\cdots & \\mathbf{u}_m \\\\\n",
    "\\vert & & \\vert \\\\\n",
    "\\end{array}\\right] \\ : \\ \\in \\mathbb{R}^{m \\times (m-r)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\widetilde{\\mathbf{U}}= \\left[\\begin{array}{cc}\n",
    "\\mathbf{U}  & \\mathbf{U}_\\perp\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "The diagonal matrix $\\mathbf{\\Sigma}$ \n",
    "\n",
    "$$\n",
    "\\mathbf{\\Sigma} = \\left[\\begin{array}{ccc}\n",
    "\\sigma_1 & &  \\\\\n",
    " & \\ddots & \\\\\n",
    " & & \\sigma_r \\\\\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "is extended to a matrix $\\widetilde{\\mathbf{\\Sigma}} \\in \\mathbb{R}^{m \\times n}$\n",
    "\n",
    "$$\n",
    "\\widetilde{\\mathbf{\\Sigma}} = \\left[\\begin{array}{cc}\n",
    "\\mathbf{\\Sigma} & \\mathbf{0} \\\\\n",
    "\\mathbf{0} & \\mathbf{0}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\widetilde{\\mathbf{U}} \\cdot \n",
    "\\widetilde{\\mathbf{\\Sigma}} \\cdot \n",
    "\\widetilde{\\mathbf{V}}^T = \\left[\\begin{array}{cc}\n",
    "\\mathbf{U}  & \\mathbf{U}_\\perp\n",
    "\\end{array}\\right]  \\cdot \\left[\\begin{array}{cc}\n",
    "\\mathbf{\\Sigma} & \\mathbf{0} \\\\\n",
    "\\mathbf{0} & \\mathbf{0}\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{c}\n",
    "\\mathbf{V}^T \\\\\n",
    "\\mathbf{V}_\\perp^T\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc347d1-6ef2-4fda-ad52-852eb776a13a",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "To clarify these procedures an example is taken from `Matrix Methods for Computational Modeling and Data Analytics` .\n",
    "(Example 5-4)\n",
    "\n",
    "A $3 \\times 2$ matrix $\\mathbf{A}$ is defined:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\left[\\begin{array}{cc}\n",
    "1 & \\sqrt{2} \\\\\n",
    "1 & \\sqrt{2} \\\\\n",
    "1 & \\sqrt{2} \n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "The two columns are linearly dependent. Thus the column rank is `1`. (The dimension of the column space is `1`).\n",
    "\n",
    "Eigenvalues are obtained from $\\mathbf{A}^T \\mathbf{A}$.\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^T \\mathbf{A} = \\left[\\begin{array}{cc}\n",
    "3 &  3 \\sqrt{2} \\\\\n",
    "3 \\sqrt{2} & 6\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "(it is easy to realise that the matrix has linearly dependent rows / columns.)\n",
    "\n",
    "Eigenvalues are computed from the characteristic polynomial.\n",
    "\n",
    "$$\n",
    "det \\left(\\begin{array}{cc}\n",
    "3 - \\lambda &  3 \\sqrt{2} \\\\\n",
    "3 \\sqrt{2} & 6 - \\lambda\n",
    "\\end{array}\\right) = \\left(3 - \\lambda\\right) \\cdot \\left(6 - \\lambda\\right) - 18 = \\lambda^2 - 9 \\lambda =  0 \n",
    "$$\n",
    "\n",
    "$\\lambda_1 = 9$ and $\\lambda_2 = 0$.\n",
    "\n",
    "Corresponding eigenvectors $\\mathbf{v}_1$ and $\\mathbf{v}_2$ are found as:\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_1 = \\left[\\begin{array}{c}\n",
    "1/\\sqrt{3} \\\\\n",
    "\\sqrt{2}/\\sqrt{3}\n",
    "\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_2 = \\left[\\begin{array}{c}\n",
    "\\sqrt{2}/\\sqrt{3} \\\\\n",
    "-1/\\sqrt{3}\n",
    "\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "Singular values are:\n",
    "\n",
    "$\\sigma_1 = \\sqrt{\\lambda_1} = 3$  and $\\sigma_2 = \\sqrt{\\lambda_2} = 0$\n",
    "\n",
    "Since $r=1$ the singular vector $\\mathbf{u}_1$ is computed:\n",
    "\n",
    "$$\n",
    "\\mathbf{u}_1 = \\frac{1}{\\sigma_1} \\mathbf{A} \\mathbf{v}_1 = \\frac{1}{3} \\left[\\begin{array}{c}\n",
    "3/\\sqrt{3} \\\\\n",
    "3/\\sqrt{3} \\\\\n",
    "3/\\sqrt{3}\n",
    "\\end{array}\\right] = \\left[\\begin{array}{c}\n",
    "1/\\sqrt{3} \\\\\n",
    "1/\\sqrt{3} \\\\\n",
    "1/\\sqrt{3}\n",
    "\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "The remaining left singular vectors $\\mathbf{u}_2$, $\\mathbf{u}_3$ are computed using the orthonormality condition.\n",
    "\n",
    "**without justification**\n",
    "\n",
    "Remaining vectors are computed from $\\mathbf{A} \\cdot \\mathbf{u} = \\mathbf{0}$\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{ccc}\n",
    "1 & 1 & 1 \\\\\n",
    "\\sqrt{2} & \\sqrt{2} & \\sqrt{2}\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{c}\n",
    "x_1 \\\\ x_2 \\\\ x_3\n",
    "\\end{array}\\right] = \\left[\\begin{array}{c}\n",
    "0 \\\\ 0\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "We must solve for $x_1 + x_2 + x_3 = 0$ and assume that $x_1, x_2$ are so called `free` variables.\n",
    "\n",
    "$x_3 = -x_1 - x_2$\n",
    "\n",
    "Then $\\mathbf{u}_2$, $\\mathbf{u}_3$ must be of the form\n",
    "\n",
    "$$\n",
    "\\mathbf{u} = \\left[\\begin{array}{c}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "-x_1 - x_2\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "To determine $\\mathbf{u}_2$ we may freely choose $x_1,\\ x_2$ and normalise the vector. \n",
    "\n",
    "$$\n",
    "\\mathbf{u}_2 = \\left[\\begin{array}{c}\n",
    "1/\\sqrt{2} \\\\\n",
    "0 \\\\\n",
    "-1/\\sqrt{2}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "To determine $\\mathbf{u}_3$ we exploit the condition $\\mathbf{u}_2^T \\cdot \\mathbf{u} = 0$.\n",
    "\n",
    "$$\\begin{gather}\n",
    "\\mathbf{u}_3 = \\left[\\begin{array}{ccc}\n",
    "1/\\sqrt{2} & 0 & -1/\\sqrt{2}\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{c}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "-x_1 - x_2\n",
    "\\end{array}\\right] = 2 x_1/\\sqrt{2} + x_2/\\sqrt{2} = 0 \\\\\n",
    "\\ \\\\\n",
    "x_2 = - 2 x_1\n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbf{u}_3 = \\left[\\begin{array}{c}\n",
    "x_1 \\\\\n",
    "-2 x_1 \\\\\n",
    "x_1\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{u}_3 = \\frac{1}{\\sqrt{6}} \\cdot \\left[\\begin{array}{c}\n",
    "1 \\\\\n",
    "-2 \\\\\n",
    "1\n",
    "\\end{array}\\right] = \\left[\\begin{array}{c}\n",
    "1/\\sqrt{6} \\\\\n",
    "-2/\\sqrt{6} \\\\\n",
    "1/\\sqrt{6}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "\n",
    "A this point we can express matrices $\\mathbf{U}$, $\\mathbf{\\Sigma}$ and $\\mathbf{V}$:\n",
    "\n",
    "$$\n",
    "\\mathbf{U} = \\left[\\begin{array}{c}\n",
    "1/\\sqrt{3} \\\\\n",
    "1/\\sqrt{3} \\\\\n",
    "1/\\sqrt{3}\n",
    "\\end{array}\\right] \\ \\ \\mathbf{\\Sigma} = \\left[\\begin{array}{c}3\\end{array}\\right] \\ \\ \\mathbf{V} = \\left[\\begin{array}{c}\n",
    "1/\\sqrt{3} \\\\\n",
    "\\sqrt{2}/\\sqrt{3}\n",
    "\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "$$\\begin{gather}\n",
    "\\mathbf{A} = \\left[\\begin{array}{c}\n",
    "1/\\sqrt{3} \\\\\n",
    "1/\\sqrt{3} \\\\\n",
    "1/\\sqrt{3}\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{c}3\\end{array}\\right] \\cdot \\left[\\begin{array}{cc}\n",
    "1/\\sqrt{3} & \\sqrt{2}/\\sqrt{3}\n",
    "\\end{array}\\right] \\\\\n",
    "\\ = \\left[\\begin{array}{c}\n",
    "1/\\sqrt{3} \\\\\n",
    "1/\\sqrt{3} \\\\\n",
    "1/\\sqrt{3}\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{cc}\n",
    "\\sqrt{3} & \\sqrt{2} \\sqrt{3}\n",
    "\\end{array}\\right] \n",
    "\\ = \\left[\\begin{array}{cc}\n",
    "1 & \\sqrt{2} \\\\\n",
    "1 & \\sqrt{2} \\\\\n",
    "1 & \\sqrt{2} \n",
    "\\end{array}\\right] \n",
    "\\end{gather} \n",
    "$$\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe6dd65-c175-4f78-9980-96864c2ddc64",
   "metadata": {},
   "source": [
    "## The SVD for $m \\lt n$\n",
    "\n",
    "The idea is to compute the `SVD` of matrix $\\mathbf{A}^T$. Once the matrices of the `SVD` have been found simply transpose the matrix product of the `SVD` to get a factorisation of matrix $\\mathbf{A}$.\n",
    "\n",
    "Here are the steps:\n",
    "\n",
    "**step#1:**  compute eigenvalues and eigenvectors of the symmetric matrix $\\mathbf{A} \\cdot \\mathbf{A}^T$\n",
    "\n",
    "Matrix $\\mathbf{A} \\cdot \\mathbf{A}^T \\in \\mathbf{m \\times m}$ has in general $r \\le m$ non-zero eigenvalues. $\\lambda_1 \\ge \\lambda_2 \\cdots \\lambda_r \\gt 0 = \\lambda_{r+1} = \\cdots = \\lambda_m$.\n",
    "\n",
    "with corresponding eigenvectors $\\mathbf{u}_1, \\ldots, \\mathbf{u}_r,\\ \\mathbf{u}_{r+1},\\ \\ldots, \\ \\mathbf{u}_m$. \n",
    "\n",
    "**step#2:** Definition of singular values $\\sigma_j = ||\\mathbf{A}^T \\cdot \\mathbf{u}_j|| = \\sqrt{\\lambda_j}$\n",
    "\n",
    "Clearly singular values are zero for $j \\gt r$.\n",
    "\n",
    "**step#3:** Define vectors $\\mathbf{v}_j = \\mathbf{A}^T \\cdot \\frac{1}{\\sigma_j} \\mathbf{u}_j  \\ for \\ j=1,\\ldots, r$. \n",
    "\n",
    "Additionally define orthonormal vectors $\\mathbf{v}_{r+1},\\ \\ldots,\\ \\mathbf{v}_{n}$. These vectors are found as solutions of $\\mathbf{A} \\cdot \\mathbf{v} = \\mathbf{0}$. \n",
    "\n",
    "**step#4** Combine what has been found so far.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98035672-f989-401c-a35a-24252193a58a",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "We want to find the `SVD` of the $2 \\times 3$ matrix\n",
    "\n",
    "$$\\mathbf{A}= \\left[\\begin{array}{ccc}\n",
    "1 & 2 & 1 \\\\\n",
    "-1 & -2 & -1\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Since $m = 2 \\lt n = 3$ we determine the `SVD` of the transpose $\\mathbf{A}^T$ first:\n",
    "\n",
    "$$\\mathbf{A}^T = \\left[\\begin{array}{cc}\n",
    "1 & -1\\\\\n",
    "2 & -2 \\\\\n",
    "1 & -1 \n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Eigenvalues must be computed from $\\mathbf{A} \\mathbf{A}^T \\in \\mathbb{R}^{2 \\times 2}$:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\mathbf{A}^T = \\left[\\begin{array}{cc}\n",
    "6 & -6 \\\\\n",
    "-6 & 6\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "For the characteristic polynomial we obtain\n",
    "\n",
    "$$\n",
    "\\left(6-\\lambda\\right)^2 - 36 = \\lambda^2 - 12 \\lambda = \\lambda \\cdot \\left(\\lambda - 12 \\right]\n",
    "$$\n",
    "\n",
    "Eigenvalues are $\\lambda_1 = 12$ and $\\lambda_2 = 0$.\n",
    "\n",
    "Eigenvector $\\mathbf{v}_1$ is found solving\n",
    "\n",
    "$$\\begin{gather}\n",
    "\\left[\\begin{array}{cc}\n",
    "-6 & -6 \\\\\n",
    "-6 & -6\n",
    "\\end{array}\\right] \\cdot \\mathbf{v}_1 = \\left[\\begin{array}{c}\n",
    "0 \\\\ 0\n",
    "\\end{array}\\right] \\\\\n",
    "\\mathbf{v}_1 = \\left[\\begin{array}{c}\n",
    "1/\\sqrt{2} \\\\ -1/\\sqrt{2}\n",
    "\\end{array}\\right] \n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "For the reduced form of the `SVD` eigenvector $\\mathbf{v}_2$ need not be dermined because the corresponding eigenvalue $\\lambda_2=0$. But here we compute it anyway from\n",
    "\n",
    "$$\\begin{gather}\n",
    "\\left[\\begin{array}{cc}\n",
    "6 & -6 \\\\\n",
    "-6 & 6\n",
    "\\end{array}\\right] \\cdot \\mathbf{v}_2 = \\left[\\begin{array}{c}\n",
    "0 \\\\ 0\n",
    "\\end{array}\\right] \\\\\n",
    "\\mathbf{v}_2 = \\left[\\begin{array}{c}\n",
    "1/\\sqrt{2} \\\\ 1/\\sqrt{2}\n",
    "\\end{array}\\right] \n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "Obviously $\\mathbf{v}_1 \\perp \\mathbf{v}_2$. \n",
    "\n",
    "Singular values are found as: $\\sigma_1= \\sqrt{12}$ and $\\sigma_2 = 0$.\n",
    "\n",
    "Hence matrix $\\mathbf{\\Sigma}$ is simply:\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbf{\\Sigma} = \\left[\\begin{array}{c}\n",
    "\\sqrt{12}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "$\\mathbf{u}_1$ is computed from $\\mathbf{A}^T \\cdot \\mathbf{v}_1 / \\sigma_1$.\n",
    "\n",
    "$$\n",
    "\\mathbf{u}_1 = \\frac{1}{\\sqrt{12}} \\cdot \\left[\\begin{array}{cc}\n",
    "1 & -1\\\\\n",
    "2 & -2 \\\\\n",
    "1 & -1 \n",
    "\\end{array}\\right] \\left[\\begin{array}{c}\n",
    "1/\\sqrt{2} \\\\ -1/\\sqrt{2}\n",
    "\\end{array}\\right] =  \\left[\\begin{array}{c}\n",
    "1/\\sqrt{6} \\\\ \n",
    "2/\\sqrt{6} \\\\\n",
    "1/\\sqrt{6}  \n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "The reduced `SVD` can now be written as:\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^T = \\left[\\begin{array}{c}\n",
    "1/\\sqrt{6} \\\\ \n",
    "2/\\sqrt{6} \\\\\n",
    "1/\\sqrt{6}  \n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{c}\n",
    "\\sqrt{12}\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{cc}\n",
    "1/\\sqrt{2} & -1/\\sqrt{2}\n",
    "\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "The `SVD`for $\\mathbf{A}$ is found by transposing.\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\left[\\begin{array}{c}\n",
    "1/\\sqrt{2} \\\\ -1/\\sqrt{2}\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{c}\n",
    "\\sqrt{12}\n",
    "\\end{array}\\right] \\cdot  \n",
    "\\left[\\begin{array}{ccc}\n",
    "1/\\sqrt{6} & 2/\\sqrt{6} & 1/\\sqrt{6}  \n",
    "\\end{array}\\right] =\n",
    "\\left[\\begin{array}{c}\n",
    "1/\\sqrt{2} \\\\ -1/\\sqrt{2}\n",
    "\\end{array}\\right] \\cdot   \n",
    "\\left[\\begin{array}{ccc}\n",
    "\\sqrt{2} & 2 \\sqrt{2} & \\sqrt{2}  \n",
    "\\end{array}\\right] = \\left[\\begin{array}{ccc}\n",
    "1 & 2 & 1 \\\\\n",
    "-1 & -2 & -1\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa0971c-421a-4dfe-9eff-d5c0c5540066",
   "metadata": {},
   "source": [
    "## Final Summary on `Singular Value Decomposition`\n",
    "\n",
    "Starting point is the matrix $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ with $rank(\\mathbf{A}) = r$. For the full `SVD` there are matrices $\\widetilde{\\mathbf{U}} \\in \\mathbb{R}^{m \\times m}$ and $\\widetilde{\\mathbf{V}} \\in \\mathbb{R}^{n \\times n}$.\n",
    "\n",
    "Each of these matrices has orthonormal columns. The matrices are partioned into submatrices like this:\n",
    "\n",
    "$$\n",
    "\\widetilde{\\mathbf{U}} = \\left[\\begin{array}{cc}\n",
    "\\mathbf{U} & \\mathbf{U}_\\perp\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\widetilde{\\mathbf{V}} = \\left[\\begin{array}{cc}\n",
    "\\mathbf{V} & \\mathbf{V}_\\perp\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{U} = \\left[\\begin{array}{ccc}\n",
    "\\vert & & \\vert \\\\\n",
    "\\mathbf{u}_1 & & \\mathbf{u}_r \\\\\n",
    "\\vert & & \\vert\n",
    "\\end{array}\\right] \\in \\mathbb{R}^{m \\times r} \\ \\ \\ \\\n",
    "\\mathbf{U}_\\perp = \\left[\\begin{array}{ccc}\n",
    "\\vert & & \\vert \\\\\n",
    "\\mathbf{u}_{r+1} & & \\mathbf{u}_m \\\\\n",
    "\\vert & & \\vert \\\\\n",
    "\\end{array}\\right] \\in \\mathbb{R}^{m \\times (m-r)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{V} = \\left[\\begin{array}{ccc}\n",
    "\\vert & & \\vert \\\\\n",
    "\\mathbf{v}_1 & & \\mathbf{v}_r \\\\\n",
    "\\vert & & \\vert\n",
    "\\end{array}\\right] \\in \\mathbb{R}^{n \\times r} \\ \\ \\ \\\n",
    "\\mathbf{V}_\\perp = \\left[\\begin{array}{ccc}\n",
    "\\vert & & \\vert \\\\\n",
    "\\mathbf{v}_{r+1} & & \\mathbf{v}_n \\\\\n",
    "\\vert & & \\vert \\\\\n",
    "\\end{array}\\right] \\in \\mathbb{R}^{n \\times (n-r)}\n",
    "$$\n",
    "\n",
    "The diagonal matrix $\\widetilde{\\mathbf{\\Sigma}}$ is composed by these submatrices:\n",
    "\n",
    "$$\n",
    "\\widetilde{\\mathbf{\\Sigma}} = \\left[\\begin{array}{cc}\n",
    "\\mathbf{\\Sigma} & \\mathbf{0} \\\\\n",
    "\\mathbf{0} & \\mathbf{0}\n",
    "\\end{array}\\right] \\in \\mathbb{R}^{m \\times n}\n",
    "$$\n",
    "\n",
    "$\\mathbf{\\Sigma} = diag\\left(\\sigma_1 \\ge \\sigma_2 \\ge \\cdots \\ge \\sigma_r \\gt 0 \\right)$\n",
    "\n",
    "**reduced SVD**\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\mathbf{U} \\cdot \\mathbf{\\Sigma} \\cdot \\mathbf{V}^T\n",
    "$$\n",
    "\n",
    "**dyadic SVD**\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\sum_{j=1}^r \\sigma_j \\cdot \\mathbf{u}_j \\cdot \\mathbf{v}_j^T\n",
    "$$\n",
    "\n",
    "**full SVD**\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\widetilde{\\mathbf{U}} \\cdot \\widetilde{\\mathbf{\\Sigma}} \\cdot \\widetilde{\\mathbf{V}}^T\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fee18c-7c22-4566-b7f1-c90a8b3baf81",
   "metadata": {},
   "source": [
    "## Properties derived from the SVD\n",
    "\n",
    "The 4 subspace are reviewed again and it is shown how they related to properties of the `SVD`.\n",
    "\n",
    "**column space**\n",
    "\n",
    "$R(\\mathbf{A} = \\left\\{\\mathbf{A} \\mathbf{x} \\ : \\ \\mathbf{x} \\in \\mathbb{R}^n  \\right\\} \\subset \\mathbb{R}^m$\n",
    "\n",
    "linear combination of `n` column vectors of $\\mathbf{A}$.\n",
    "\n",
    "**row space**\n",
    "\n",
    "$R(\\mathbf{A}^T = \\left\\{\\mathbf{A}^T \\mathbf{y} \\ : \\ \\mathbf{y} \\in \\mathbb{R}^m  \\right\\} \\subset \\mathbb{R}^n$\n",
    "\n",
    "linear combination of `m` row vectors of $\\mathbf{A}$.\n",
    "\n",
    "**null space**\n",
    "\n",
    "$N(\\mathbf{A}) = \\left\\{\\mathbf{x} \\in \\mathbb{R}^n \\ : \\ \\mathbf{A} \\mathbf{x} = \\mathbf{0} \\right\\} \\subset \\mathbb{R}^n$\n",
    "\n",
    "a possible interpretation: vector $\\mathbf{x}$ is orthogonal to all row vectors of $\\mathbf{A}$.\n",
    "\n",
    "**left null space**\n",
    "\n",
    "$N(\\mathbf{A}^T) = \\left\\{\\mathbf{y} \\in \\mathbb{R}^m \\ : \\ \\mathbf{A}^T \\mathbf{y} = \\mathbf{0} \\right\\} \\subset \\mathbb{R}^m$\n",
    "\n",
    "a possible interpretation: vector $\\mathbf{y}$ is orthogonal to all column vectors of $\\mathbf{A}$.\n",
    "\n",
    "**Proof**\n",
    "\n",
    "A vector in the column space is orthogonal to a vector in the left null space.\n",
    "\n",
    "Let $\\mathbf{z}_{cs} = \\mathbf{A} \\mathbf{x}$ be a vector in the column space and $\\mathbf{z}_{ln}$ be a vector in the left null space. The orthogonality is proved like this:\n",
    "\n",
    "$$\\begin{gather}\n",
    " \\mathbf{z}_{cs}^T \\cdot \\mathbf{z}_{ln} =  \\mathbf{x}^T \\cdot \\underbrace{\\mathbf{A}^T \\cdot \\mathbf{z}_{ln}}_{\\mathbf{0}} = \\mathbf{0}\n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "In an analogous way it can be shown that any vector in the row space is orthogonal to any vector in the null space.\n",
    "\n",
    "---\n",
    "\n",
    "Next we show that vectors in the column space are in the subspace spanned by left singular vectors $\\mathbf{u}_1, \\cdots, \\mathbf{u}_r$.\n",
    "\n",
    "$$\n",
    "R(\\mathbf{A}) = span \\left\\{\\mathbf{u}_1, \\cdots, \\mathbf{u}_r \\right\\}\n",
    "$$\n",
    "\n",
    "To show this we use the dyadic form of the `SVD`:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\sum_{j=1}^r \\sigma_j \\cdot \\mathbf{u}_j \\mathbf{v}_j^T\n",
    "$$\n",
    "\n",
    "$\\mathbf{A} \\cdot \\mathbf{x}$ is therefore\n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\cdot \\mathbf{x} = \\sum_{j=1}^r \\sigma_j \\cdot \\mathbf{u}_j \\mathbf{v}_j^T \\cdot \\mathbf{x} =  \\sum_{j=1}^r \\left(\\sigma_j \\cdot \\mathbf{v}_j^T \\cdot \\mathbf{x}\\right) \\cdot \\mathbf{u}_j \n",
    "$$\n",
    "\n",
    "It shows that $\\mathbf{A} \\cdot \\mathbf{x}$ is just a linear combination of the left singular vectors $\\mathbf{u}_1, \\cdots, \\mathbf{u}_r$.\n",
    "\n",
    "To show that each vector $\\mathbf{u}_k$ is also in $R(\\mathbf{A})$ we must show that $\\mathbf{u}_k$ can be expressed by some appropriately chosen vector $\\mathbf{x}$ such that\n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\cdot \\mathbf{x} = \\mathbf{u}_k\n",
    "$$\n",
    "\n",
    "From\n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\cdot \\mathbf{x} = \\sum_{j=1}^r \\sigma_j \\cdot \\mathbf{u}_j \\mathbf{v}_j^T \\cdot \\mathbf{x} \n",
    "$$\n",
    "\n",
    "and the orthonormality of right singular vectors we just set $\\mathbf{x} = \\frac{1}{\\sigma_k} \\mathbf{v}_k$.\n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\cdot \\frac{1}{\\sigma_k} \\mathbf{v}_k = \\mathbf{A} \\cdot \\mathbf{x} = \\sum_{j=1}^r  \\frac{\\sigma_j}{\\sigma_k} \\cdot \\mathbf{u}_j \\mathbf{v}_j^T \\cdot \\mathbf{v}_k = \\mathbf{u}_k\n",
    "$$\n",
    "\n",
    "This completes the proof that $R(\\mathbf{A}) = span \\left\\{\\mathbf{u}_1, \\cdots, \\mathbf{u}_r \\right\\}$.\n",
    "\n",
    "---\n",
    "\n",
    "**proof** \n",
    "\n",
    "$$\n",
    "N(\\mathbf{A}^T) = span \\left\\{\\mathbf{u}_{r+1}, \\ldots,   \\mathbf{u}_{m}\\right\\}\n",
    "$$\n",
    "\n",
    "All left singular vectors $\\mathbf{u}_1, \\ldots, \\mathbf{u}_m$ are a orthonormal set with\n",
    "\n",
    "$$\n",
    "\\mathbb{R}^{m} = span \\left\\{ \\mathbf{u}_1, \\ldots, \\mathbf{u}_m \\right\\}\n",
    "$$\n",
    "\n",
    "On the other hand $span \\left\\{ \\mathbf{u}_1, \\ldots, \\mathbf{u}_r \\right\\} \\perp span \\left\\{ \\mathbf{u}_{r+1}, \\ldots, \\mathbf{u}_m \\right\\}$\n",
    "\n",
    "We must now show that any vector in the set $\\left\\{\\mathbf{u}_{r+1}, \\ldots,   \\mathbf{u}_{m}\\right\\}$ is a solution of\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^T \\cdot \\mathbf{u}_{k} = \\mathbf{0} \\ : \\ k = r+1, \\ldots, m\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e58390-40b0-41bb-9e13-c81571cfdd4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
