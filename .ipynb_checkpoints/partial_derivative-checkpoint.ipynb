{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ff5f5f2-a746-478d-85e5-6ed803677283",
   "metadata": {},
   "source": [
    "# Partial Derivatives\n",
    "\n",
    "Literature:\n",
    "\n",
    "`Calculus`, Paul Dawkins  (available as PDF document)\n",
    "\n",
    "`MATHEMATICS FOR MACHINE LEARNING` , Deisenroth et. al.\n",
    "\n",
    "**Scope**\n",
    "\n",
    "1) Review of some concepts of partial derivatives\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db998e08-67c1-439e-97d5-21365a0cc9d2",
   "metadata": {},
   "source": [
    "## Multivariate Functions\n",
    "\n",
    "A multivariate function $f(x_1, x_2, ..., x_N)$ depends on $N$ independent variables $[x_1, x_2, ..., x_N]$. To keep it simple these variables shall be real. The result $y$ of the multivariate function can be a scalar or a vector. But here only the scalar case shall be considered. Moreover it shall be assumed that $y$ is a real number.\n",
    "\n",
    "$$\n",
    "y = f(x_1, x_2, ..., x_N)\n",
    "$$\n",
    "\n",
    "The independent variables are summarized into a vector:\n",
    "\n",
    "$$\n",
    "\\mathbf{x} = \\left[  \n",
    "\\begin{array}{c}\n",
    "x_1 \\\\\n",
    "\\vdots \\\\\n",
    "x_n \\\\\n",
    "\\vdots \\\\\n",
    "x_N\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "A partial derivative is defined like this:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial x_n} f(\\mathbf{x}) = \\lim_{\\Delta h \\to 0} \\ \\frac{f(x_1,\\ ...,\\ x_n + \\Delta h,\\ x_N) - f(x_1,\\ ...,\\ x_n,\\ x_N)}{\\Delta h}\n",
    "$$\n",
    "\n",
    "A vector of all partial derivatives\n",
    "\n",
    "$$\n",
    "\\mathbf{g}(\\mathbf{x}) =  \\frac{\\partial}{\\partial {\\mathbf{x}}} f(\\mathbf{x})= \\left[\n",
    "\\begin{array}{c}\n",
    "\\frac{\\partial}{\\partial x_1} f(\\mathbf{x}) \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\partial}{\\partial x_n} f(\\mathbf{x}) \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\partial}{\\partial x_N} f(\\mathbf{x})\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "is defined as *gradient* of a the multivariate function $f(\\mathbf{x})$. Here the gradient vector has been defined as a column vector. But we could have defined it as a row vector as well. It just depends on how that gradient shall be processed in subsequent steps.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de7385c-c813-44da-9b3a-95b107a8f4a0",
   "metadata": {},
   "source": [
    "## Directional Derivatives\n",
    "\n",
    "Let $\\mathbf{r}$ denote a unit vector (length 1; $|\\mathbf{r}| = 1$ with $N$ components:\n",
    "\n",
    "$$\n",
    "\\mathbf{r} = \\left[  \n",
    "\\begin{array}{c}\n",
    "r_1 \\\\\n",
    "\\vdots \\\\\n",
    "r_n \\\\\n",
    "\\vdots \\\\\n",
    "r_N\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "|\\mathbf{r}| = \\sum_{n=1}^{N} r_n^2 = 1\n",
    "$$\n",
    "\n",
    "When going from $\\mathbf{x}$ to $\\mathbf{x} + \\mathbf{r} \\cdot h$ function $f(\\mathbf{x})$ changes. The amount of change is computed here:\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x} + \\mathbf{r} \\cdot h) - f(\\mathbf{x}) = f(x_1 + r_1 \\cdot h,\\ \\ldots,\\ x_n + r_n \\cdot h,\\ \\ldots,\\ x_N + r_N \\cdot h) - f(\\mathbf{x})\n",
    "$$\n",
    "\n",
    "Defining $\\Delta x_n = r_n \\cdot h$ for $1 \\le n \\le N$ and assuming *vanishingly* small value of $h$ a reasonably good approximation of this change is:\n",
    "\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x} + \\mathbf{r} \\cdot h) - f(\\mathbf{x}) \\approx h \\cdot \\sum_{n=1}^{N} \\frac{\\partial}{\\partial x_n} f(\\mathbf{x}) \\cdot r_n\n",
    "$$\n",
    "\n",
    "The rate of change is obtained by dividing both sides of this equation by $h$:\n",
    "\n",
    "$$\n",
    "\\frac{f(\\mathbf{x} + \\mathbf{r} \\cdot h) - f(\\mathbf{x})}{h} \\approx \\sum_{n=1}^{N} \\frac{\\partial}{\\partial x_n} f(\\mathbf{x}) \\cdot r_n\n",
    "$$\n",
    "\n",
    "In the limit of $h \\to 0$ the rate of change converges to the directional derivative $D_{\\mathbf{r}} f(\\mathbf{x})$ (in the direction of vector $\\mathbf{r}$:\n",
    "\n",
    "$$\n",
    "D_{\\mathbf{r}} f(\\mathbf{x}) = \\lim_{h \\to 0} \\frac{f(\\mathbf{x} + \\mathbf{r} \\cdot h) - f(\\mathbf{x})}{h} = \\sum_{n=1}^{N} \\frac{\\partial}{\\partial x_n} f(\\mathbf{x}) \\cdot r_n\n",
    "$$\n",
    "\n",
    "More commonly the directional derivative may be expressed as the dot product of the *gradient* vector and the *directional* vector:\n",
    "\n",
    "$$\n",
    "D_{\\mathbf{r}} f(\\mathbf{x}) = \\left[\\begin{array}{ccccc}\n",
    "\\frac{\\partial}{\\partial x_1} f(\\mathbf{x}) & \\dots & \\frac{\\partial}{\\partial x_n} f(\\mathbf{x}) & \\dots & \\frac{\\partial}{\\partial x_N} f(\\mathbf{x})\n",
    "\\end{array}  \\right] \\cdot\n",
    "\\left[  \n",
    "\\begin{array}{c}\n",
    "r_1 \\\\\n",
    "\\vdots \\\\\n",
    "r_n \\\\\n",
    "\\vdots \\\\\n",
    "r_N\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "**Summary**\n",
    "\n",
    "1) If the directional vector $\\mathbf{r}$ has the same direction as the gradient vector the directional derivative $D_{\\mathbf{r}} f(\\mathbf{x})$ is maximized.\n",
    "\n",
    "2) If vector  $\\mathbf{r}$ is orthogonal to the gradient vector the directional derivative is $0$ (no change in this direction).\n",
    "\n",
    "3) The direction of *steepest descent* is the gradient vector with each vector component multiplied by $-1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82a2c41-a19f-4e43-a3bd-ab0f42cac86c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
