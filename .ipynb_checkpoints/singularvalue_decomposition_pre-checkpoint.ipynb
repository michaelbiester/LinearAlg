{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bcab729-9af1-4a5b-a3ec-cc10ab3ff664",
   "metadata": {},
   "source": [
    "# Singular Value Decomposition\n",
    "\n",
    "Sources:\n",
    "\n",
    "  1) `Linear Algebra : Theory, Intuition, Code` author: Mike X Cohen, publisher: sincXpress\n",
    "\n",
    "  2)  `Matrix Methods for Computational Modeling and Data Analytics` author: Mark Embree, Virginia Tech\n",
    "\n",
    "This notebook has been setup to understand how singular value decomposition works. The content is mainly an adaption of the chapter 16 of `Linear Algebra : Theory, Intuition, Code` and of chapter 5 `The singular value decomposition` of `Matrix Methods for Computational Modeling and Data Analytics`. I have used mostly `Matrix Methods for Computational Modeling and Data Analytics` because to me it seems more accessible than `Linear Algebra : Theory, Intuition, Code` .\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8d617bb-6084-46c1-a2e2-3acfe6ee6a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some imports for numerical experiments\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca58188-162f-4a75-8848-9126ea7866e1",
   "metadata": {},
   "source": [
    "## Derivation of Singular Value Decomposition\n",
    "\n",
    "mainly from `Matrix Methods for Computational Modeling and Data Analytics` \n",
    "\n",
    "All columns of matrix $\\mathbf{A} \\in \\mathbb{R}^{m \\times n} \\ : \\ m \\ge n$ shall be linearly independent. Thus the rank of the matrix is as large as possible.\n",
    "\n",
    "From $\\mathbf{A}$ a square matrix $\\mathbf{A}^T \\cdot \\mathbf{A} \\in \\mathbb{R}^{m \\times m}$ is constructed. This matrix is symmetric and it is also *positive-definite* $\\mathbf{x}^T \\cdot \\mathbf{A}^T \\cdot \\mathbf{A} \\cdot \\mathbf{x} \\ge 0$\n",
    "\n",
    "An implication of $\\mathbf{A}^T \\cdot \\mathbf{A}$ being `positive-definite` is that its eigenvalues are positive.\n",
    "\n",
    "We can therefore find pairs of eigenvalues/eigenvectors $\\lambda_j,\\ \\mathbf{v}_j \\ : \\ 1 \\le j le n$. Also the ordering of these pair is arbitrary we assume descending ordering of eigenvalues such as $\\lambda_1 \\ge \\lambda_2 \\ge \\ldots \\ge \\lambda_n \\gt 0$.\n",
    "\n",
    "Eigenvectors $\\mathbf{v}_j$ have unit length $||\\mathbf{v}_j|| = 1$. Moreover they are mutually orthonormal $\\mathbf{v}_j^T \\cdot \\mathbf{v}_k = 0 \\ for \\ j \\neq k$.\n",
    "\n",
    "Since we have \n",
    "\n",
    "$$\\begin{gather}\n",
    "\\mathbf{v}_j^T \\cdot \\mathbf{A}^T \\cdot \\mathbf{A} \\cdot \\mathbf{v}_j = \\left(\\mathbf{A} \\cdot \\mathbf{v}_j\\right)^T \\cdot \\left(\\mathbf{A} \\cdot \\mathbf{v}_j \\right) = \\lambda_j \\cdot \\mathbf{v}_j^T \\cdot \\mathbf{v}_j = \\lambda_j = ||\\mathbf{A} \\cdot \\mathbf{v}_j ||^2 \\\\\n",
    "\\to \\\\\n",
    "\\sqrt{\\lambda_j} = ||\\mathbf{A} \\cdot \\mathbf{v}_j ||\n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "The positive square root of eigenvalue $\\lambda_j$ is defined as *singular value* $\\sigma_j$.\n",
    "\n",
    "$$\n",
    "\\sigma_j = \\sqrt{\\lambda_j} = ||\\mathbf{A} \\cdot \\mathbf{v}_j ||\n",
    "$$\n",
    "\n",
    "and because we arranged eigenvalues in decreasing order we get $\\sigma_1 \\ge \\sigma_2 \\ge  \\ldots \\ge \\sigma_n \\gt 0$ (singular values of $\\mathbf{A}$).\n",
    "\n",
    "Now we define new vectors $\\mathbf{u}_j = \\mathbf{A} \\cdot \\frac{\\mathbf{v}_j}{\\sigma_j}$.\n",
    "\n",
    "The vectors have *unit length* and they are *mutually orthonormal*. These properties are derived here:\n",
    "\n",
    "The unit length property follows directly from\n",
    "\n",
    "$$\n",
    "||\\mathbf{u}_j||^2 = \\left(\\mathbf{A} \\cdot \\frac{\\mathbf{v}_j}{\\sigma_j}\\right)^T \\cdot \\mathbf{A} \\cdot \\frac{\\mathbf{v}_j}{\\sigma_j} = \\frac{1}{\\sigma_j^2} \\cdot ||\\mathbf{A} \\cdot \\mathbf{v}_j||^2 = 1\n",
    "$$\n",
    "\n",
    "Orthogonality is proved like this:\n",
    "\n",
    "$$\n",
    "\\mathbf{u}_j^T \\cdot \\mathbf{u}_k = \\left(\\mathbf{A} \\cdot \\frac{\\mathbf{v}_j}{\\sigma_j}\\right)^T \\cdot \\mathbf{A} \\cdot \\frac{\\mathbf{v}_k}{\\sigma_k} = \\frac{1}{\\sigma_j \\cdot \\sigma_k} \\cdot \\mathbf{v}_j^T \\cdot \\mathbf{A}^T \\mathbf{A} \\cdot \\mathbf{v}_k = \\frac{\\lambda_k}{\\sigma_j \\cdot \\sigma_k} \\cdot \\underbrace{\\mathbf{v}_j^T \\cdot \\mathbf{v}_k}_{0 \\ : \\ j \\neq k}\n",
    "$$\n",
    "\n",
    "**Summary**\n",
    "\n",
    "$$\n",
    "\\sigma_j \\cdot \\mathbf{u}_j = \\mathbf{A} \\cdot \\mathbf{v}_j\n",
    "$$\n",
    "\n",
    "Arranging the column vectors of both sides of the equation yields a matrix equation:\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{cccc}\n",
    "\\vert & \\vert & & \\vert \\\\\n",
    "\\mathbf{A} \\mathbf{v}_1 & \\mathbf{A} \\mathbf{v}_2 & \\cdots & \\mathbf{A} \\mathbf{v}_n \\\\\n",
    "\\vert & \\vert & & \\vert\n",
    "\\end{array}\\right] = \\left[\\begin{array}{cccc}\n",
    "\\vert & \\vert & & \\vert \\\\\n",
    "\\sigma_1 \\mathbf{u}_1 & \\sigma_2 \\mathbf{u}_2 & \\cdots & \\sigma_n \\mathbf{u}_n \\\\\n",
    "\\vert & \\vert & & \\vert \\\\\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Each side of the matrix equation can be further decomposed into a product of matrices:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\cdot \\underbrace{\\left[\\begin{array}{cccc}\n",
    "\\vert & \\vert & & \\vert \\\\\n",
    "\\mathbf{v}_1 & \\mathbf{v}_2 & \\cdots & \\mathbf{v}_n \\\\\n",
    "\\vert & \\vert & & \\vert\n",
    "\\end{array}\\right]}_{\\mathbf{V}} = \\underbrace{\\left[\\begin{array}{cccc}\n",
    "\\vert & \\vert & & \\vert \\\\\n",
    "\\mathbf{u}_1 & \\mathbf{u}_2 & \\cdots & \\mathbf{u}_n \\\\\n",
    "\\vert & \\vert & & \\vert \\\\\n",
    "\\end{array}\\right]}_{\\mathbf{U}} \\cdot \\underbrace{\\left[\\begin{array}{cccc}\n",
    "\\sigma_1 & & & \\\\\n",
    " & \\sigma_2 & & \\\\\n",
    " & & \\ddots & \\\\\n",
    "  & & & \\sigma_n\n",
    "\\end{array}\\right]}_{\\mathbf{\\Sigma}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\cdot \\mathbf{V} = \\mathbf{U} \\cdot \\mathbf{\\Sigma}\n",
    "$$\n",
    "\n",
    "$\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$, $\\mathbf{V} \\in \\mathbb{R}^{n \\times n}$, $\\mathbf{U} \\in \\mathbb{R}^{m \\times n}$ and $\\mathbf{\\Sigma} \\in \\mathbb{R}^{n \\times n}$\n",
    "\n",
    "Since $\\mathbf{V}^T \\mathbf{V} = \\mathbf{I}$ we have $\\mathbf{V}^{-1} = \\mathbf{V}^T$. Therefore $\\mathbf{V} \\cdot \\mathbf{V}^T =  \\mathbf{V} \\cdot \\mathbf{V}^{-1} = \\mathbf{I}$.\n",
    "\n",
    "\n",
    "$$\\begin{gather}\n",
    "\\mathbf{A} \\cdot \\mathbf{V} \\cdot \\mathbf{V}^T = \\mathbf{U} \\cdot \\mathbf{\\Sigma} \\cdot \\mathbf{V}^T \\\\\n",
    "\\to \\\\\n",
    "\\mathbf{A} = \\mathbf{U} \\cdot \\mathbf{\\Sigma} \\cdot \\mathbf{V}^T \n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37983ea1-49e2-4833-8957-b45b26b6886d",
   "metadata": {},
   "source": [
    "### A worked example\n",
    "\n",
    "Given a $3 \\times 2$ matrix $\\mathbf{A}$.\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\left[\\begin{array}{cc}\n",
    "1 & 1 \\\\\n",
    "0 & 0 \\\\\n",
    "\\sqrt{2} & -\\sqrt{2}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^T \\mathbf{A} = \\left[\\begin{array}{cc}\n",
    "3 & -1  \\\\\n",
    "-1 & 3\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "\n",
    "Eigenvalues of $\\mathbf{A}^T \\mathbf{A}$ are computed from the characteristic polynomial.\n",
    "\n",
    "$$\n",
    "det \\left(\\begin{array}{cc}\n",
    "3 -\\lambda & -1  \\\\\n",
    "-1 & 3-\\lambda\n",
    "\\end{array}\\right) = \\left(9 - 6 \\cdot \\lambda + \\lambda^2 - 1 \\right) = \\lambda^2 - 6 \\cdot \\lambda + 8\n",
    "$$\n",
    "\n",
    "Eigenvalues are: $\\lambda_1 = 4$ and $\\lambda_2 = 2$. The corresponding eigenvectors $\\mathbf{v}_1$ and $\\mathbf{v}_2$ are computed from:\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{cc}\n",
    "3-4 & -1  \\\\\n",
    "-1 & 3-4\n",
    "\\end{array}\\right] = \\left[\\begin{array}{cc}\n",
    "-1 & -1  \\\\\n",
    "-1 & -1\n",
    "\\end{array}\\right] = \n",
    "\\left[\\begin{array}{c}\n",
    "0 \\\\\n",
    "0 \n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_1 = \\left[\\begin{array}{c}\n",
    "1/\\sqrt{2} \\\\\n",
    "-1/\\sqrt{2}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{cc}\n",
    "3-2 & -1  \\\\\n",
    "-1 & 3-2\n",
    "\\end{array}\\right] = \\left[\\begin{array}{cc}\n",
    "1 & -1  \\\\\n",
    "-1 & 1\n",
    "\\end{array}\\right] = \n",
    "\\left[\\begin{array}{c}\n",
    "0 \\\\\n",
    "0 \n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_2 = \\left[\\begin{array}{c}\n",
    "1/\\sqrt{2} \\\\\n",
    "1/\\sqrt{2}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Accordingly singular values are: $\\sigma_1 = \\sqrt{\\lambda_1} = 2$ and $\\sigma_2 = \\sqrt{\\lambda_2} = \\sqrt{2}$.\n",
    "\n",
    "In the next step vectors $\\mathbf{u}_1$ and $\\mathbf{u}_2$ are computed.\n",
    "\n",
    "$$\n",
    "\\mathbf{u}_1 =  \\mathbf{A} \\cdot \\frac{\\mathbf{v}_1}{\\sigma_1} = \\frac{1}{2} \\cdot \\left[\\begin{array}{cc}\n",
    "1 & 1 \\\\\n",
    "0 & 0 \\\\\n",
    "\\sqrt{2} & -\\sqrt{2}\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{c}\n",
    "1/\\sqrt{2} \\\\\n",
    "-1/\\sqrt{2}\n",
    "\\end{array}\\right] = \\left[\\begin{array}{c}\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "1\n",
    "\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{u}_2 =  \\mathbf{A} \\cdot \\frac{\\mathbf{v}_2}{\\sigma_2} = \\frac{1}{\\sqrt{2}} \\cdot \\left[\\begin{array}{cc}\n",
    "1 & 1 \\\\\n",
    "0 & 0 \\\\\n",
    "\\sqrt{2} & -\\sqrt{2}\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{c}\n",
    "1/\\sqrt{2} \\\\\n",
    "1/\\sqrt{2}\n",
    "\\end{array}\\right] = \\left[\\begin{array}{c}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "0\n",
    "\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "\n",
    "We are now able to write the matrix decomposition:\n",
    "\n",
    "$$\n",
    "\\underbrace{\\left[\\begin{array}{cc}\n",
    "1 & 1 \\\\\n",
    "0 & 0 \\\\\n",
    "\\sqrt{2} & -\\sqrt{2}\n",
    "\\end{array}\\right]}_{\\mathbf{A}} = \\underbrace{\\left[\\begin{array}{cc}\n",
    "0 & 1 \\\\\n",
    "0 & 0 \\\\\n",
    "1 & 0 \n",
    "\\end{array}\\right]}_{\\mathbf{U}} \\cdot \\underbrace{\\left[\\begin{array}{cc}\n",
    "2 & 0 \\\\\n",
    "0 & \\sqrt{2}\n",
    "\\end{array}\\right]}_{\\mathbf{\\Sigma}} \\cdot \\underbrace{\\left[\\begin{array}{cc}\n",
    "1/\\sqrt{2} & -1/\\sqrt{2}\\\\\n",
    "1/\\sqrt{2} & 1/\\sqrt{2}\n",
    "\\end{array}\\right]}_{\\mathbf{\\mathbf{V}}^T}\n",
    "$$\n",
    "\n",
    "Below is a numerical example using `Numpy`.\n",
    "\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.linalg.svd.html\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d42e65-4138-4151-ae4b-c23cba474841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amat         :\n",
      "[[ 1.          1.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 1.41421356 -1.41421356]]\n",
      "\n",
      "Umat         :\n",
      "[[ 4.01572963e-17 -1.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [-1.00000000e+00 -1.79477306e-16]]\n",
      "\n",
      "SingularVals :\n",
      "[2.         1.41421356]\n",
      "\n",
      "Vtmat        :\n",
      "[[-0.70710678  0.70710678]\n",
      " [-0.70710678 -0.70710678]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# numerical example\n",
    "Amat = np.array([[1,1], [0,0], [math.sqrt(2), -math.sqrt(2)]])\n",
    "\n",
    "Umat, SingularVals, Vtmat = np.linalg.svd(Amat, full_matrices=False)\n",
    "\n",
    "print(f\"Amat         :\\n{Amat}\\n\")\n",
    "print(f\"Umat         :\\n{Umat}\\n\")\n",
    "print(f\"SingularVals :\\n{SingularVals}\\n\")\n",
    "print(f\"Vtmat        :\\n{Vtmat}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edff5e77-28fd-4b3b-8da5-b2a88d260862",
   "metadata": {},
   "source": [
    "\n",
    "**Note**\n",
    "\n",
    "`Umat` is equivalent to $-\\mathbf{U}$ and `Vtmat` is equivalent to $-\\mathbf{V}^T$. So these signs cancel each other.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c250af-72fe-4ac1-8825-fe9d4a3b6a1b",
   "metadata": {},
   "source": [
    "## Another Way to formulate the `SVD`\n",
    "\n",
    "Again a matrix $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ with linearly independent columns is assumed.\n",
    "\n",
    "The singular value decomposition has been found as:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\mathbf{U} \\cdot \\mathbf{\\Sigma} \\cdot \\mathbf{V}^T \n",
    "$$\n",
    "\n",
    "With the matrix product $\\mathbf{U} \\cdot \\mathbf{\\Sigma}$ expressed as:\n",
    "\n",
    "$$\n",
    "\\mathbf{U} \\cdot \\mathbf{\\Sigma} = \\left[\\begin{array}{cccc}\n",
    "\\vert & \\vert & & \\vert \\\\\n",
    "\\sigma_1 \\mathbf{u}_1 & \\sigma_2 \\mathbf{u}_2 & \\cdots & \\sigma_n \\mathbf{u}_n \\\\\n",
    "\\vert & \\vert & & \\vert\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "matrix $\\mathbf{A}$ is written like this:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\left[\\begin{array}{cccc}\n",
    "\\vert & \\vert & & \\vert \\\\\n",
    "\\sigma_1 \\mathbf{u}_1 & \\sigma_2 \\mathbf{u}_2 & \\cdots & \\sigma_n \\mathbf{u}_n \\\\\n",
    "\\vert & \\vert & & \\vert\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{ccc}\n",
    "- & \\mathbf{v}_1^T & - \\\\\n",
    "- & \\mathbf{v}_2^T & - \\\\\n",
    "  & \\cdots & \\\\\n",
    "- & \\mathbf{v}_n^T & - \n",
    "\\end{array}\\right] = \\sum_{j=1}^n \\sigma_1 \\cdot \\mathbf{u}_j \\cdot \\mathbf{v}_j^T\n",
    "$$\n",
    "\n",
    "Therefore the `SVD` of $\\mathbf{A}$ may be expressed as the sum of `n` submatrices $\\sigma_1 \\cdot \\mathbf{u}_j \\cdot \\mathbf{v}_j$.\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\sum_{j=1}^n \\sigma_1 \\cdot \\mathbf{u}_j \\cdot \\mathbf{v}_j^T \n",
    "$$\n",
    "\n",
    "To illustrate this equation we use again \n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\left[\\begin{array}{cc}\n",
    "1 & 1 \\\\\n",
    "0 & 0 \\\\\n",
    "\\sqrt{2} & -\\sqrt{2}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "and decompose it into\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\sum_{j=1}^{2} \\sigma_j \\cdot \\mathbf{u}_j \\cdot \\mathbf{v}_j^T  = \\sigma_1 \\cdot \\mathbf{u}_1 \\cdot \\mathbf{v}_1^T + \\sigma_2 \\cdot \\mathbf{u}_2 \\cdot \\mathbf{v}_2^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\left[\\begin{array}{cc}\n",
    "1 & 1 \\\\\n",
    "0 & 0 \\\\\n",
    "\\sqrt{2} & -\\sqrt{2}\n",
    "\\end{array}\\right] = \n",
    "2 \\cdot \\left[\\begin{array}{c}\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "1\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{cc}\n",
    "1/\\sqrt{2} & -1/\\sqrt{2}\n",
    "\\end{array}\\right] + \\sqrt{2} \\cdot \\left[\\begin{array}{c}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "0\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{cc}\n",
    "1/\\sqrt{2} & 1/\\sqrt{2}\n",
    "\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\left[\\begin{array}{cc}\n",
    "0 & 0 \\\\\n",
    "0 & 0 \\\\\n",
    "\\sqrt{2} & -\\sqrt{2}\n",
    "\\end{array}\\right] + \\left[\\begin{array}{cc}\n",
    "1 & 1 \\\\\n",
    "0 & 0 \\\\\n",
    "0 & 0\n",
    "\\end{array}\\right] = \\left[\\begin{array}{cc}\n",
    "1 & 1 \\\\\n",
    "0 & 0 \\\\\n",
    "\\sqrt{2} & -\\sqrt{2}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fe303d-cd99-4951-841f-b1574095ca99",
   "metadata": {},
   "source": [
    "### A simple application\n",
    "\n",
    "The `SVD` shall be used to solve the matrix equation $\\mathbf{A} \\cdot \\mathbf{x} = \\mathbf{b}$. Assumption for matrix $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$:  $\\mathbf{A}$ is invertible. So its inverse $\\mathbf{A}^{-1}$ exists.\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\mathbf{U} \\cdot \\mathbf{\\Sigma} \\cdot \\mathbf{V}^T = \\sum_{j=1}^n \\sigma_1 \\cdot \\mathbf{u}_j \\cdot \\mathbf{v}_j^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\cdot \\mathbf{x} = \\mathbf{U} \\cdot \\mathbf{\\Sigma} \\cdot \\mathbf{V}^T \\cdot \\mathbf{x} = \\sum_{j=1}^n \\sigma_1 \\cdot \\mathbf{u}_j \\cdot \\left(\\mathbf{v}_j^T \\cdot \\mathbf{x} \\right) = \\mathbf{b}\n",
    "$$\n",
    "\n",
    "Using $\\mathbf{U}^T \\cdot \\mathbf{U} = \\mathbf{I}$ we obtain:\n",
    "\n",
    "$$\\begin{gather}\n",
    "\\mathbf{U}^T \\cdot \\mathbf{U} \\cdot \\mathbf{\\Sigma} \\cdot \\mathbf{V}^T \\cdot \\mathbf{x} = \\mathbf{U}^T \\cdot \\mathbf{b} \\\\\n",
    "\\mathbf{\\Sigma} \\cdot \\mathbf{V}^T \\cdot \\mathbf{x} = \\mathbf{U}^T \\cdot \\mathbf{b}\n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "With the inverse matrix \n",
    "\n",
    "$$\n",
    "\\mathbf{\\Sigma}^{-1} = \\left[\\begin{array}{cccc}\n",
    "1/\\sigma_1 &  &  & \\\\\n",
    "& 1/\\sigma_2 & & \\\\\n",
    "& & \\ddots & \\\\\n",
    "& & & 1/\\sigma_n\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "we have \n",
    "\n",
    "$$\\begin{gather}\n",
    "\\mathbf{\\Sigma}^{-1} \\cdot \\mathbf{\\Sigma} \\cdot \\mathbf{V}^T \\cdot \\mathbf{x} = \\mathbf{\\Sigma}^{-1} \\cdot \\mathbf{U}^T \\cdot \\mathbf{b} \\\\\n",
    "\\mathbf{V}^T \\cdot \\mathbf{x} = \\mathbf{\\Sigma}^{-1} \\cdot \\mathbf{U}^T \\cdot \\mathbf{b} \\\\\n",
    "\\mathbf{V} \\cdot \\mathbf{V}^T \\cdot \\mathbf{x} = \\mathbf{V} \\cdot \\mathbf{\\Sigma}^{-1} \\cdot \\mathbf{U}^T \\cdot \\mathbf{b} \\\\\n",
    "\\to \\\\\n",
    "\\mathbf{x} = \\mathbf{V} \\cdot \\mathbf{\\Sigma}^{-1} \\cdot \\mathbf{U}^T \\cdot \\mathbf{b}\n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "We conclude that\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^{-1} = \\mathbf{V} \\cdot \\mathbf{\\Sigma}^{-1} \\cdot \\mathbf{U}^T = \\sum_{j=1}^n \\frac{1}{\\sigma_j} \\mathbf{v}_j \\cdot \\mathbf{u}_j^T\n",
    "$$\n",
    "\n",
    "$$\\begin{gather}\n",
    "\\mathbf{x} = \\mathbf{A}^{-1} \\cdot \\mathbf{b} = \\sum_{j=1}^n \\frac{1}{\\sigma_j} \\mathbf{v}_j \\cdot \\left(\\mathbf{u}_j^T \\cdot \\mathbf{b}\\right) \\\\\n",
    "\\mathbf{x} = \\sum_{j=1}^n \\left(\\frac{\\mathbf{u}_j^T \\cdot \\mathbf{b}}{\\sigma_j}\\right) \\cdot \\mathbf{v}_j  \n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "We see that $\\mathbf{x}$ is the weighted addition of eigenvectors $\\mathbf{v}_1,\\ \\mathbf{v}_2,\\ldots,\\ \\mathbf{v}_n$ of symmetric matrix $\\mathbf{A}^T \\mathbf{A}$.\n",
    "\n",
    "The next section is about the `Full SVD`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3d329c-f479-4cd8-8356-01d7d428d4fb",
   "metadata": {},
   "source": [
    "## Full SVD \n",
    "\n",
    "Assumption are the same as for the reduced version of the `SVD`.\n",
    "\n",
    "1) $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ with $m \\ge n$.\n",
    "\n",
    "2) Again the `n` columns of the matrix shall be linearly independent.\n",
    "\n",
    "Contrary to the reduced version of the `SVD` where matrix $\\mathbf{U} \\in \\mathbb{R}^{m \\times n}$ has `n` orthonormal columns, we generate an `augmented `matrix $\\widetilde{\\mathbf{U}} \\in \\mathbb{R}^{m \\times m}$ by adding $m-n$ *extra* column vectors to the reduced matrix $\\mathbf{U}$. Finally all column vectors of $\\widetilde{\\mathbf{U}}$ are mutally orthonormal.\n",
    "\n",
    "**ToDo**\n",
    "\n",
    "The exact procedure to achieve these extra column vectors should be made more explicit. Here we just postulate that such augmentation is feasible.\n",
    "\n",
    "The orthonormal column vectors of the augmented matrix $\\widetilde{\\mathbf{U}}$ are denoted $\\mathbf{u}_1,\\ \\mathbf{u}_2,\\ \\ldots, \\mathbf{u}_n,\\ \\mathbf{u}_{n+1},\\ \\ldots ,\\ \\mathbf{u}_m$.\n",
    "\n",
    "$$\n",
    "\\widetilde{\\mathbf{U}} = \\left[\\begin{array}{cccccc}\n",
    "\\vert & & \\vert & \\vert & & \\vert \\\\\n",
    "\\mathbf{u}_1 & \\cdots & \\mathbf{u}_n & \\mathbf{u}_{n+1} & \\cdots & \\mathbf{u}_m \\\\\n",
    "\\vert & & \\vert & \\vert & & \\vert \n",
    "\\end{array}\\right] \\in \\mathbb{R}^{m \\times m}\n",
    "$$\n",
    "\n",
    "Since $\\widetilde{\\mathbf{U}}$ is square with `m` orthonormal columns we have:\n",
    "\n",
    "$$\n",
    "\\widetilde{\\mathbf{U}}^T \\widetilde{\\mathbf{U}} = \\mathbf{I}\n",
    "$$\n",
    "\n",
    "Moreover $\\widetilde{\\mathbf{U}}^{-1} = \\widetilde{\\mathbf{U}}^T $.\n",
    "\n",
    "The matrix $\\mathbf{\\Sigma} \\in \\mathbb{R}^{n \\times n}$ (already defined in the reduced `SVD`) is augmented to another matrix $\\widetilde{\\mathbf{\\Sigma}} \\in \\mathbb{R}^{m \\times n}$ by inserting $m-n$ zero values row vectors below the n`th row of $\\mathbf{\\Sigma}$.\n",
    "\n",
    "$$\n",
    "\\widetilde{\\mathbf{\\Sigma}} = \\left[\\begin{array}{c}\n",
    "\\mathbf{\\Sigma} \\\\\n",
    "\\underbrace{\\mathbf{0}}_{(m-n) \\times n}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Having augmented matrix $\\mathbf{U}$ by $m-n$ additional orthonormal columns to a matrix $\\widetilde{\\mathbf{U}}$ and extended matrix $\\mathbf{\\Sigma}$ by inserting $m-n$ zero rows to a matrix $\\widetilde{mathbf{\\Sigma}}$ we can now write the `Full SVD`.\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\widetilde{\\mathbf{U}} \\cdot \\widetilde{\\mathbf{\\Sigma}} \\cdot \\mathbf{V}^T\n",
    "$$\n",
    "\n",
    "As for the `reduced SVD` a numerical example shows some more details.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45be0247-4197-4ba3-a086-b6b37d19c65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amat                     :\n",
      "[[ 1.          1.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 1.41421356 -1.41421356]]\n",
      "\n",
      "Umat (augmented)         :\n",
      "[[ 4.01572963e-17 -1.00000000e+00 -1.81298661e-16]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.00000000e+00]\n",
      " [-1.00000000e+00 -1.79477306e-16  1.28197512e-16]]\n",
      "\n",
      "SingularVals (augmented) :\n",
      "[2.         1.41421356]\n",
      "\n",
      "Vtmat                    :\n",
      "[[-0.70710678  0.70710678]\n",
      " [-0.70710678 -0.70710678]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# numerical example\n",
    "Amat = np.array([[1,1], [0,0], [math.sqrt(2), -math.sqrt(2)]])\n",
    "\n",
    "Umat, SingularVals, Vtmat = np.linalg.svd(Amat, full_matrices=True)\n",
    "\n",
    "print(f\"Amat                     :\\n{Amat}\\n\")\n",
    "print(f\"Umat (augmented)         :\\n{Umat}\\n\")\n",
    "print(f\"SingularVals (augmented) :\\n{SingularVals}\\n\")\n",
    "print(f\"Vtmat                    :\\n{Vtmat}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9586dff2-e12b-487f-90b3-2ec5be337511",
   "metadata": {},
   "source": [
    "## Review (so far)\n",
    "\n",
    "We have so far dealt with two representations of the `SVD`:\n",
    "\n",
    "1) the `reduced SVD`\n",
    "\n",
    "2) the `full SVD`\n",
    "\n",
    "But for both cases we have made the <ins>same assumption</ins> regarding matrix $\\mathbf{A}$: The $m \\times n : m \\ge n$ matrix has full columns rank. $rank(\\mathbf{A}) = n$.\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66843bef-2d0c-445d-9d8b-49e91756be6b",
   "metadata": {},
   "source": [
    "## `Reduced SVD` : General case $m \\ge n$\n",
    "\n",
    "Now we consider a more general case:\n",
    "\n",
    "1) $m \\ge n$\n",
    "\n",
    "2) the columns of $\\mathbf{A}$ need to be all linearly independent.\n",
    "\n",
    "If there a linearly dependent columns of $\\mathbf{A}$ there exist some vector $\\mathbf{v} \\in \\mathbb{R}^n$ for which we have:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\cdot \\mathbf{v} = \\mathbf{0} \\ : \\ \\mathbf{v}\\neq \\mathbf{0} \n",
    "$$\n",
    "\n",
    "Multiplying this equation from the left by $\\mathbf{A}^T$ yields:\n",
    "\n",
    "$$\\begin{gather}\n",
    "\\mathbf{A}^T \\cdot \\mathbf{A} \\cdot \\mathbf{v} = \\mathbf{0} \\\\ \n",
    "\\mathbf{A}^T \\cdot \\mathbf{A} \\cdot \\mathbf{v} = 0 \\cdot \\mathbf{v}\n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "Vector $\\mathbf{v}$ is therefore an eigenvector of $\\mathbf{A}^T \\cdot \\mathbf{A}$ with eigenvalue $\\lambda = 0$. \n",
    "\n",
    "All vectors $\\mathbf{v}$ which satisfy $\\mathbf{A} \\cdot \\mathbf{v} = \\mathbf{0}$ are then eigenvectors with eigenvalue `0`.\n",
    "\n",
    "There a $r :\\ 0 \\le r \\le n$ non-zero eigenvalues $\\lambda_1 \\ge \\lambda_2 \\ge \\cdots \\ge \\lambda_r \\gt 0$. And there are $n-r$ zero eigenvalues $\\lambda_{r+1} = \\cdots =\\lambda_n = 0$.\n",
    "\n",
    "To these eigenvalues belong eigenvectors $\\mathbf{v}_1, \\mathbf{v}_2,\\ \\cdots ,\\mathbf{v}_n$.\n",
    "\n",
    "**Without Proof**\n",
    "\n",
    "1) Eigenvectors $\\mathbf{v}_{r+1}, \\ \\cdots ,\\mathbf{v}_n$ form a basis of the null space $R(\\mathbf{A})$. The basis vectors are orthonormal (proof required)\n",
    "\n",
    "2) Moreover $\\mathbf{v}_{r+1}, \\ \\cdots ,\\mathbf{v}_n$ are orthonormal to $\\mathbf{v}_1, \\ \\cdots ,\\mathbf{v}_r$ (proof required)\n",
    "\n",
    "Building the expression for the SVD proceeds in similar steps as before ..\n",
    "\n",
    "Define `singular values` $\\mathbf{\\sigma_j}$:\n",
    "\n",
    "$$\n",
    "\\mathbf{\\sigma_j} = \\sqrt{\\left(\\mathbf{A} \\cdot \\mathbf{v} \\right)^T \\cdot \\left(\\mathbf{A} \\cdot \\mathbf{v} \\right)} = ||\\mathbf{A} \\cdot \\mathbf{v}|| = \\sqrt{\\lambda_j} \\:\\ j=1,\\ldots, n\n",
    "$$\n",
    "\n",
    "Clearly $\\sigma_1 \\ge \\sigma_2 \\ge \\cdots \\ge \\sigma_r \\gt 0 $ and $\\sigma_{r+1} = \\cdots = \\sigma_n = 0 $\n",
    "\n",
    "Define orthonormal vectors $\\mathbf{u}_j$\n",
    "\n",
    "$$\n",
    "\\mathbf{u}_j = \\frac{1}{\\sigma_j} \\mathbf{A} \\cdot \\mathbf{v} : \\ j=1, \\ldots, r\n",
    "$$\n",
    "\n",
    "Augment the set of vectors $\\mathbf{u}_1, \\cdots, \\mathbf{u}_r$ by vectors $\\mathbf{u}_{r+1}, \\cdots, \\mathbf{u}_n$. (provide steps to do this)\n",
    "\n",
    "Due to its definition we also have:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\cdot \\mathbf{v}_j = \\sigma_j \\cdot \\mathbf{u}_j : j=1, \\ldots,\\ n\n",
    "$$\n",
    "\n",
    "And since $\\mathbf{A} \\cdot \\mathbf{v}_j = \\mathbf{0} : j = r+1,\\ldots,\\ n$ also $\\mathbf{u}_j = \\mathbf{u}_j \\ :\\ j = r+1,\\ldots,\\ n$.\n",
    "\n",
    "Now with $\\mathbf{A} \\cdot \\mathbf{v}_j = \\sigma_j \\cdot \\mathbf{u}_j : j=1, \\ldots,\\ n$ everything is ready to formulate the `SVD`.\n",
    "\n",
    "\n",
    "$$\\begin{align}\n",
    "\\left[\\begin{array}{cccccc} \n",
    "\\vert & & \\vert & \\vert & & \\vert \\\\\n",
    "\\mathbf{A} \\cdot \\mathbf{v}_1 & \\cdots & \\mathbf{A} \\cdot \\mathbf{v}_r & \\mathbf{A} \\cdot \\mathbf{v}_{r+1} & \\cdots & \\mathbf{A} \\cdot \\mathbf{v}_n \\\\\n",
    "\\vert & & \\vert & \\vert & & \\vert \n",
    "\\end{array}\\right] = \\left[\\begin{array}{cccccc}\n",
    "\\vert & & \\vert & \\vert & & \\vert \\\\\n",
    "\\sigma_1 \\cdot \\mathbf{u}_1 & \\cdots & \\sigma_r \\cdot \\mathbf{u}_r & \\sigma_{r+1} \\cdot \\mathbf{u}_{r+1} & \\cdots & \\sigma_n \\cdot \\mathbf{u}_n \\\\\n",
    "\\vert & & \\vert & \\vert & & \\vert \\\\\n",
    "\\end{array}\\right] = \\left[\\begin{array}{cccccc}\n",
    "\\vert & & \\vert & \\vert & & \\vert \\\\\n",
    "\\sigma_1 \\cdot \\mathbf{u}_1 & \\cdots & \\sigma_r \\cdot \\mathbf{u}_r & \\mathbf{0} & \\cdots & \\mathbf{0} \\\\\n",
    "\\vert & & \\vert & \\vert & & \\vert \\\\\n",
    "\\end{array}\\right]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "As before the matrices on either side of the equation can be expressed as products of matrices:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\cdot \n",
    "\\left[\\begin{array}{cccccc} \n",
    "\\vert & & \\vert & \\vert & & \\vert \\\\\n",
    "\\mathbf{v}_1 & \\cdots & \\mathbf{v}_r & \\mathbf{v}_{r+1} & \\cdots & \\mathbf{v}_n \\\\\n",
    "\\vert & & \\vert & \\vert & & \\vert \n",
    "\\end{array}\\right] = \\left[\\begin{array}{ccc}\n",
    "\\vert & & \\vert \\\\\n",
    "\\mathbf{u}_1 & \\cdots & \\mathbf{u}_r \\\\\n",
    "\\vert & & \\vert \\\\\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{ccccccc}\n",
    "\\sigma_1 & &  & \\vert & 0 & \\cdots & 0 \\\\\n",
    " & \\ddots &  & \\vert & \\vdots & \\ddots & \\vdots \\\\\n",
    " & & \\sigma_r &  \\vert & 0 & \\cdots & 0\n",
    "\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "\n",
    "In the next step we define to matrices $\\mathbf{V}$  and $\\mathbf{V}_\\perp$ :\n",
    "\n",
    "$$\n",
    "\\mathbf{V} = \\left[\\begin{array}{ccc}\n",
    "\\vert & & \\vert \\\\\n",
    "\\mathbf{v}_1 & \\cdots & \\mathbf{v}_r \\\\\n",
    "\\vert & & \\vert \\\\\n",
    "\\end{array}\\right] \\ : \\ \\in \\mathbb{R}^{n \\times r} \\ \\ \\\n",
    "\\mathbf{V}_\\perp = \\left[\\begin{array}{ccc}\n",
    "\\vert & & \\vert \\\\\n",
    "\\mathbf{v}_{r+1} & \\cdots & \\mathbf{v}_n \\\\\n",
    "\\vert & & \\vert \\\\\n",
    "\\end{array}\\right] \\ : \\ \\in \\mathbb{R}^{n \\times (n-r)}\n",
    "$$\n",
    "\n",
    "These matrices are concatenated into a single matrix $\\widetilde{\\mathbf{V}} \\in \\mathbb{R}^{n \\times n}$.\n",
    "\n",
    "$$\n",
    "\\widetilde{\\mathbf{V}}  = \\left[\\begin{array}{cc}\n",
    "\\mathbf{V} & \\mathbf{V}_\\perp\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "All columns of $\\widetilde{\\mathbf{V}}$ are mutually orthonormal. Therefore \n",
    "\n",
    "$$\\begin{gather}\n",
    "\\widetilde{\\mathbf{V}}^T \\cdot \\widetilde{\\mathbf{V}} = \\widetilde{\\mathbf{V}} \\cdot \\widetilde{\\mathbf{V}}^T = \\mathbf{I} \\\\\n",
    "\\widetilde{\\mathbf{V}}^{-1} = \\widetilde{\\mathbf{V}}^T\n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "Similarly we define matrix $\\mathbf{U}$ as the concatenation of `r` column vectors $\\mathbf{u}_1,\\ \\ldots, \\ \\mathbf{u}_r$.\n",
    "\n",
    "$$\n",
    "\\mathbf{U} = \\left[\\begin{array}{ccc}\n",
    "\\vert & & \\vert \\\\\n",
    "\\mathbf{u}_1 & \\cdots & \\mathbf{u}_r \\\\\n",
    "\\vert & & \\vert \\\\\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "And the `r` singualar values are put into a diagonal matrix $\\mathbf{\\Sigma} \\in \\mathbf{R}^{n \\times n}$.\n",
    "\n",
    "$$\n",
    "\\mathbf{\\Sigma} = \\left[\\begin{array}{ccc}\n",
    "\\sigma_1 & &  \\\\\n",
    " & \\ddots & \\\\\n",
    " & & \\sigma_r \\\\\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "\n",
    "With these definitions we get \n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\cdot \\widetilde{\\mathbf{V}} = \\mathbf{U} \\cdot \\left[\\begin{array}{cc}\n",
    "\\mathbf{\\Sigma} & \\mathbf{0} \\\\\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Multiplying both sides of the equation from the right by $\\widetilde{\\mathbf{V}}^T$ we obtain:\n",
    "\n",
    "$$\\begin{gather}\n",
    "\\mathbf{A} \\cdot \\widetilde{\\mathbf{V}} \\widetilde{\\mathbf{V}}^T = \\mathbf{U} \\cdot \\left[\\begin{array}{cc}\n",
    "\\mathbf{\\Sigma} & \\mathbf{0} \\\\\n",
    "\\end{array}\\right] \\cdot \\widetilde{\\mathbf{V}}^T \\\\\n",
    "\\mathbf{A} = \\mathbf{U} \\cdot \\left[\\begin{array}{cc}\n",
    "\\mathbf{\\Sigma} & \\mathbf{0} \\\\\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{cc}\n",
    "\\mathbf{V} & \\mathbf{V}_\\perp\n",
    "\\end{array}\\right]^T \\\\\n",
    "\\mathbf{A} = \\mathbf{U} \\cdot \\left[\\begin{array}{cc}\n",
    "\\mathbf{\\Sigma} & \\mathbf{0} \\\\\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{c}\n",
    "\\mathbf{V}^T \\\\\n",
    "\\mathbf{V}_\\perp^T\n",
    "\\end{array}\\right] \\\\\n",
    "\\mathbf{A} = \\mathbf{U} \\cdot \n",
    "\\mathbf{\\Sigma} \\cdot \n",
    "\\mathbf{V}^T \n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "The last equation looks like the `reduced SVD` for the full rank case. However the dimension of the matrices involved have been changed.\n",
    "\n",
    "$\\mathbf{U} \\in \\mathbb{R}^{m \\times r}$, $\\mathbf{\\Sigma} \\in \\mathbb{R}^{r \\times r}$ and $\\mathbf{V} \\in \\mathbb{R}^{n \\times r}$.\n",
    "\n",
    "**Summary**\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\mathbf{U} \\cdot \n",
    "\\mathbf{\\Sigma} \\cdot \n",
    "\\mathbf{V}^T = \\underbrace{\\left[\\begin{array}{ccc}\n",
    "\\vert & & \\vert \\\\\n",
    "\\mathbf{u}_1 & \\cdots & \\mathbf{u}_r \\\\\n",
    "\\vert & & \\vert \\\\\n",
    "\\end{array}\\right]}_{m \\times r} \\cdot \\underbrace{\\left[\\begin{array}{ccc}\n",
    "\\sigma_1 & &  \\\\\n",
    " & \\ddots & \\\\\n",
    " & & \\sigma_r \\\\\n",
    "\\end{array}\\right]}_{r \\times r} \\cdot \\underbrace{\\left[\\begin{array}{ccc}\n",
    "- &  \\mathbf{v}_1^T & - \\\\\n",
    " & \\vdots & \\\\\n",
    "- & \\mathbf{v}_r^T & - \n",
    "\\end{array}\\right]}_{r \\times n} = \\sum_{j=1}^r \\sigma_j \\cdot \\mathbf{u}_j \\cdot \\mathbf{v}_j^T \n",
    "$$\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390b8ed1-d1e0-4597-bd99-616da6baabde",
   "metadata": {},
   "source": [
    "### The full SVD : General case $m \\ge n$\n",
    "\n",
    "As in the reduced SVD case we use \n",
    "\n",
    "$$\n",
    "\\mathbf{V} = \\left[\\begin{array}{ccc}\n",
    "\\vert & & \\vert \\\\\n",
    "\\mathbf{v}_1 & \\cdots & \\mathbf{v}_r \\\\\n",
    "\\vert & & \\vert \\\\\n",
    "\\end{array}\\right] \\ : \\ \\in \\mathbb{R}^{n \\times r} \\ \\ \\\n",
    "\\mathbf{V}_\\perp = \\left[\\begin{array}{ccc}\n",
    "\\vert & & \\vert \\\\\n",
    "\\mathbf{v}_{r+1} & \\cdots & \\mathbf{v}_n \\\\\n",
    "\\vert & & \\vert \\\\\n",
    "\\end{array}\\right] \\ : \\ \\in \\mathbb{R}^{n \\times (n-r)} \\ \\ \\\n",
    "\\widetilde{\\mathbf{V}}= \\left[\\begin{array}{cc}\n",
    "\\mathbf{V}  & \\mathbf{V}_\\perp\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "In a similar fashion we define a matrix $\\widetilde{\\mathbf{U}} \\in \\mathbb{R}^{m \\times m}$ which is constructed from thr concatenation of matrices $\\mathbf{U} \\in \\mathbb{R}^{m \\times r}$ and $\\mathbf{U}_\\perp \\in \\mathbb{R}^{m \\times (m-r)}$.\n",
    "\n",
    "$$\n",
    "\\mathbf{U} = \\left[\\begin{array}{ccc}\n",
    "\\vert & & \\vert \\\\\n",
    "\\mathbf{u}_1 & \\cdots & \\mathbf{u}_r \\\\\n",
    "\\vert & & \\vert \\\\\n",
    "\\end{array}\\right] \\ : \\ \\in \\mathbb{R}^{m \\times r} \\ \\ \\\n",
    "\\mathbf{U}_\\perp = \\left[\\begin{array}{ccc}\n",
    "\\vert & & \\vert \\\\\n",
    "\\mathbf{u}_{r+1} & \\cdots & \\mathbf{u}_m \\\\\n",
    "\\vert & & \\vert \\\\\n",
    "\\end{array}\\right] \\ : \\ \\in \\mathbb{R}^{m \\times (m-r)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\widetilde{\\mathbf{U}}= \\left[\\begin{array}{cc}\n",
    "\\mathbf{U}  & \\mathbf{U}_\\perp\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "The diagonal matrix $\\mathbf{\\Sigma}$ \n",
    "\n",
    "$$\n",
    "\\mathbf{\\Sigma} = \\left[\\begin{array}{ccc}\n",
    "\\sigma_1 & &  \\\\\n",
    " & \\ddots & \\\\\n",
    " & & \\sigma_r \\\\\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "is extended to a matrix $\\widetilde{\\mathbf{\\Sigma}} \\in \\mathbb{R}^{m \\times n}$\n",
    "\n",
    "$$\n",
    "\\widetilde{\\mathbf{\\Sigma}} = \\left[\\begin{array}{cc}\n",
    "\\mathbf{\\Sigma} & \\mathbf{0} \\\\\n",
    "\\mathbf{0} & \\mathbf{0}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\widetilde{\\mathbf{U}} \\cdot \n",
    "\\widetilde{\\mathbf{\\Sigma}} \\cdot \n",
    "\\widetilde{\\mathbf{V}}^T = \\left[\\begin{array}{cc}\n",
    "\\mathbf{U}  & \\mathbf{U}_\\perp\n",
    "\\end{array}\\right]  \\cdot \\left[\\begin{array}{cc}\n",
    "\\mathbf{\\Sigma} & \\mathbf{0} \\\\\n",
    "\\mathbf{0} & \\mathbf{0}\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{c}\n",
    "\\mathbf{V}^T \\\\\n",
    "\\mathbf{V}_\\perp^T\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc347d1-6ef2-4fda-ad52-852eb776a13a",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "To clarify these procedures an example is taken from `Matrix Methods for Computational Modeling and Data Analytics` .\n",
    "(Example 5-4)\n",
    "\n",
    "A $3 \\times 2$ matrix $\\mathbf{A}$ is defined:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\left[\\begin{array}{cc}\n",
    "1 & \\sqrt{2} \\\\\n",
    "1 & \\sqrt{2} \\\\\n",
    "1 & \\sqrt{2} \n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "The two columns are linearly dependent. Thus the column rank is `1`. (The dimension of the column space is `1`).\n",
    "\n",
    "Eigenvalues are obtained from $\\mathbf{A}^T \\mathbf{A}$.\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^T \\mathbf{A} = \\left[\\begin{array}{cc}\n",
    "3 &  3 \\sqrt{2} \\\\\n",
    "3 \\sqrt{2} & 6\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "(it is easy to realise that the matrix has linearly dependent rows / columns.)\n",
    "\n",
    "Eigenvalues are computed from the characteristic polynomial.\n",
    "\n",
    "$$\n",
    "det \\left(\\begin{array}{cc}\n",
    "3 - \\lambda &  3 \\sqrt{2} \\\\\n",
    "3 \\sqrt{2} & 6 - \\lambda\n",
    "\\end{array}\\right) = \\left(3 - \\lambda\\right) \\cdot \\left(6 - \\lambda\\right) - 18 = \\lambda^2 - 9 \\lambda =  0 \n",
    "$$\n",
    "\n",
    "$\\lambda_1 = 9$ and $\\lambda_2 = 0$.\n",
    "\n",
    "Corresponding eigenvectors $\\mathbf{v}_1$ and $\\mathbf{v}_2$ are found as:\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_1 = \\left[\\begin{array}{c}\n",
    "1/\\sqrt{3} \\\\\n",
    "\\sqrt{2}/\\sqrt{3}\n",
    "\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_2 = \\left[\\begin{array}{c}\n",
    "\\sqrt{2}/\\sqrt{3} \\\\\n",
    "-1/\\sqrt{3}\n",
    "\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "Singular values are:\n",
    "\n",
    "$\\sigma_1 = \\sqrt{\\lambda_1} = 3$  and $\\sigma_2 = \\sqrt{\\lambda_2} = 0$\n",
    "\n",
    "Since $r=1$ the singular vector $\\mathbf{u}_1$ is computed:\n",
    "\n",
    "$$\n",
    "\\mathbf{u}_1 = \\frac{1}{\\sigma_1} \\mathbf{A} \\mathbf{v}_1 = \\frac{1}{3} \\left[\\begin{array}{c}\n",
    "3/\\sqrt{3} \\\\\n",
    "3/\\sqrt{3} \\\\\n",
    "3/\\sqrt{3}\n",
    "\\end{array}\\right] = \\left[\\begin{array}{c}\n",
    "1/\\sqrt{3} \\\\\n",
    "1/\\sqrt{3} \\\\\n",
    "1/\\sqrt{3}\n",
    "\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "The remaining left singular vectors $\\mathbf{u}_2$, $\\mathbf{u}_3$ are computed using the orthonormality condition.\n",
    "\n",
    "**without justification**\n",
    "\n",
    "Remaining vectors are computed from $\\mathbf{A} \\cdot \\mathbf{u} = \\mathbf{0}$\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{ccc}\n",
    "1 & 1 & 1 \\\\\n",
    "\\sqrt{2} & \\sqrt{2} & \\sqrt{2}\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{c}\n",
    "x_1 \\\\ x_2 \\\\ x_3\n",
    "\\end{array}\\right] = \\left[\\begin{array}{c}\n",
    "0 \\\\ 0\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "We must solve for $x_1 + x_2 + x_3 = 0$ and assume that $x_1, x_2$ are so called `free` variables.\n",
    "\n",
    "$x_3 = -x_1 - x_2$\n",
    "\n",
    "Then $\\mathbf{u}_2$, $\\mathbf{u}_3$ must be of the form\n",
    "\n",
    "$$\n",
    "\\mathbf{u} = \\left[\\begin{array}{c}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "-x_1 - x_2\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "To determine $\\mathbf{u}_2$ we may freely choose $x_1,\\ x_2$ and normalise the vector. \n",
    "\n",
    "$$\n",
    "\\mathbf{u}_2 = \\left[\\begin{array}{c}\n",
    "1/\\sqrt{2} \\\\\n",
    "0 \\\\\n",
    "-1/\\sqrt{2}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "To determine $\\mathbf{u}_3$ we exploit the condition $\\mathbf{u}_2^T \\cdot \\mathbf{u} = 0$.\n",
    "\n",
    "$$\\begin{gather}\n",
    "\\mathbf{u}_3 = \\left[\\begin{array}{ccc}\n",
    "1/\\sqrt{2} & 0 & -1/\\sqrt{2}\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{c}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "-x_1 - x_2\n",
    "\\end{array}\\right] = 2 x_1/\\sqrt{2} + x_2/\\sqrt{2} = 0 \\\\\n",
    "\\ \\\\\n",
    "x_2 = - 2 x_1\n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbf{u}_3 = \\left[\\begin{array}{c}\n",
    "x_1 \\\\\n",
    "-2 x_1 \\\\\n",
    "x_1\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{u}_3 = \\frac{1}{\\sqrt{6}} \\cdot \\left[\\begin{array}{c}\n",
    "1 \\\\\n",
    "-2 \\\\\n",
    "1\n",
    "\\end{array}\\right] = \\left[\\begin{array}{c}\n",
    "1/\\sqrt{6} \\\\\n",
    "-2/\\sqrt{6} \\\\\n",
    "1/\\sqrt{6}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "\n",
    "A this point we can express matrices $\\mathbf{U}$, $\\mathbf{\\Sigma}$ and $\\mathbf{V}$:\n",
    "\n",
    "$$\n",
    "\\mathbf{U} = \\left[\\begin{array}{c}\n",
    "1/\\sqrt{3} \\\\\n",
    "1/\\sqrt{3} \\\\\n",
    "1/\\sqrt{3}\n",
    "\\end{array}\\right] \\ \\ \\mathbf{\\Sigma} = \\left[\\begin{array}{c}3\\end{array}\\right] \\ \\ \\mathbf{V} = \\left[\\begin{array}{c}\n",
    "1/\\sqrt{3} \\\\\n",
    "\\sqrt{2}/\\sqrt{3}\n",
    "\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "$$\\begin{gather}\n",
    "\\mathbf{A} = \\left[\\begin{array}{c}\n",
    "1/\\sqrt{3} \\\\\n",
    "1/\\sqrt{3} \\\\\n",
    "1/\\sqrt{3}\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{c}3\\end{array}\\right] \\cdot \\left[\\begin{array}{cc}\n",
    "1/\\sqrt{3} & \\sqrt{2}/\\sqrt{3}\n",
    "\\end{array}\\right] \\\\\n",
    "\\ = \\left[\\begin{array}{c}\n",
    "1/\\sqrt{3} \\\\\n",
    "1/\\sqrt{3} \\\\\n",
    "1/\\sqrt{3}\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{cc}\n",
    "\\sqrt{3} & \\sqrt{2} \\sqrt{3}\n",
    "\\end{array}\\right] \n",
    "\\ = \\left[\\begin{array}{cc}\n",
    "1 & \\sqrt{2} \\\\\n",
    "1 & \\sqrt{2} \\\\\n",
    "1 & \\sqrt{2} \n",
    "\\end{array}\\right] \n",
    "\\end{gather} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710ce58b-863a-47da-a96e-8ac163eeb47d",
   "metadata": {},
   "source": [
    "## Older stuff /Definitions \n",
    "\n",
    "The singular value decomposition is defined for the general case of rectangular $m \\times n$ matrix $\\mathbf{B}$ . It includes these cases:\n",
    "\n",
    "1) square matrix $m = n$\n",
    "\n",
    "2) tall matrix $m \\gt n$\n",
    "\n",
    "3) wide matrix $m \\lt n$\n",
    "\n",
    "The singular value decomposition is defined as a matrix product of three matrices:\n",
    "\n",
    "1) a square $m \\times m$ matrix $\\mathbf{U}$. The matrix has orthonormal column vectors.\n",
    "\n",
    "2) a rectangular $n \\times m$ matrix $\\mathbf{\\Sigma}$. The diagonal elements are the *singular values*\n",
    "\n",
    "3) a square $n \\times n$ matrix $\\mathbf{V}^T$. The matrix  $\\mathbf{V}$ has orthonormal column vectors.\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\mathbf{U} \\cdot \\mathbf{\\Sigma} \\cdot \\mathbf{V}^T\n",
    "$$\n",
    "\n",
    "The following step are needed to get the matrices of the singular value decomposition.\n",
    "\n",
    "We consider the $n \\times n$ matrix $\\mathbf{A}^T \\cdot \\mathbf{A}$. The matrix is square and symmetric. Moreover its eigendecomposition exists and its eigenvalues are positive $\\lambda \\ge 0$. Its eigenvectors are orthonormal.\n",
    "\n",
    "$$\\begin{gather}\n",
    "\\mathbf{A}^T \\cdot \\mathbf{A} = \\left(\\mathbf{U} \\cdot \\mathbf{\\Sigma} \\cdot \\mathbf{V}^T\\right)^T \\cdot \\left(\\mathbf{U} \\cdot \\mathbf{\\Sigma} \\cdot \\mathbf{V}^T \\right) \\\\\n",
    "\\mathbf{A}^T \\cdot \\mathbf{A} = \\mathbf{V} \\cdot \\mathbf{\\Sigma}^T \\cdot \\underbrace{\\mathbf{U}^T \\cdot \\mathbf{U}}_{\\mathbf{I}} \\cdot \\mathbf{\\Sigma} \\cdot \\mathbf{V}^T \\\\\n",
    "\\mathbf{A}^T \\cdot \\mathbf{A} = \\mathbf{V} \\cdot \\left(\\mathbf{\\Sigma}^T \\cdot \\mathbf{\\Sigma}\\right) \\cdot \\mathbf{V}^T \\\\\n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "Matrix $\\left(\\mathbf{\\Sigma}^T \\cdot \\mathbf{\\Sigma}\\right)$ is again $n \\times n$ diagonal matrix. Its diagonal entries are the eigenvalues of the  eigendecomposition of $\\mathbf{A}^T \\cdot \\mathbf{A}$.\n",
    "\n",
    "The expression\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^T \\cdot \\mathbf{A} = \\mathbf{V} \\cdot \\left(\\mathbf{\\Sigma}^T \\cdot \\mathbf{\\Sigma}\\right) \\cdot \\mathbf{V}^T\n",
    "$$\n",
    "\n",
    "serves to get matrices $\\mathbf{V},\\ \\left(\\mathbf{\\Sigma}^T \\cdot \\mathbf{\\Sigma}\\right) $.\n",
    "\n",
    "Using a similar procedure for the $m \\times m$ matrix $\\mathbf{A} \\cdot \\mathbf{A}^T$\n",
    "\n",
    "$$\\begin{gather}\n",
    "\\mathbf{A} \\cdot \\mathbf{A}^T = \\left(\\mathbf{U} \\cdot \\mathbf{\\Sigma} \\cdot \\mathbf{V}^T\\right) \\cdot \\left(\\mathbf{U} \\cdot \\mathbf{\\Sigma} \\cdot \\mathbf{V}^T \\right)^T \\\\\n",
    "\\ \n",
    "\\mathbf{A} \\cdot \\mathbf{A}^T = \\mathbf{U} \\cdot \\left(\\mathbf{\\Sigma} \\cdot \\mathbf{\\Sigma}^T\\right) \\cdot \\mathbf{U}^T\n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "From this equation which again a eigendecomposition the matrix $\\mathbf{U}$ is derived.\n",
    "\n",
    "**Todo**\n",
    "\n",
    "Show how get matrix $\\Sigma$ from either squares matrix $\\left(\\mathbf{\\Sigma}^T \\cdot \\mathbf{\\Sigma}\\right)$ or $\\left(\\mathbf{\\Sigma} \\cdot \\mathbf{\\Sigma}^T\\right)$.\n",
    "\n",
    "Without proof:\n",
    "\n",
    "Since $\\left(\\mathbf{\\Sigma}^T \\cdot \\mathbf{\\Sigma}\\right)$ or $\\left(\\mathbf{\\Sigma} \\cdot \\mathbf{\\Sigma}^T\\right)$ are diagonal matrices the matrix $\\mathbf{\\Sigma}$ has only non-zero entries for its diagonal elements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc45f63-7be8-4344-a767-7ecd59219959",
   "metadata": {},
   "source": [
    "## Example (solved manually)\n",
    "\n",
    "Matrix $\\mathbf{A}$ is defined as a $2 \\times 3$ matrix.\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\left[\\begin{array}{ccc}\n",
    "1 & 1 & 0 \\\\\n",
    "0 & 1 & 1\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "The matrix product $\\mathbf{A}^T \\cdot \\mathbf{A}$ which is a symmetric $3 \\times 3$ matrix the eigendecomposition exists. \n",
    "\n",
    "So lets compute (manually):\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^T \\cdot \\mathbf{A} = \n",
    "\\left[\\begin{array}{cc}\n",
    "1 & 0 \\\\\n",
    "1 & 1 \\\\\n",
    "0 & 1\n",
    "\\end{array}\\right]\n",
    "\\cdot\n",
    "\\left[\\begin{array}{ccc}\n",
    "1 & 1 & 0 \\\\\n",
    "0 & 1 & 1\n",
    "\\end{array}\\right] = \\left[\\begin{array}{ccc}\n",
    "1 & 1 & 0 \\\\\n",
    "1 & 2 & 1 \\\\\n",
    "0 & 1 & 1\n",
    "\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "The eigen decomposition of $\\mathbf{A}^T \\cdot \\mathbf{A}$ can be expressed like this:\n",
    "\n",
    "$$\n",
    "\\mathbf{B} = \\mathbf{V} \\cdot \\mathbf{\\Lambda} \\cdot \\mathbf{V}^T \n",
    "$$\n",
    "\n",
    "**computing the eigenvalues**\n",
    "\n",
    "The eigenvalues are computed from the roots of the characteristic polynomial $p(\\lambda)$.\n",
    "\n",
    "$$\n",
    "p(\\lambda) = det \\left[\\begin{array}{ccc}\n",
    "1-\\lambda & 1 & 0 \\\\\n",
    "1 & 2-\\lambda & 1 \\\\\n",
    "0 & 1 & 1-\\lambda\n",
    "\\end{array}\\right] = \\lambda \\cdot \\left(1 - \\lambda\\right) \\cdot \\left(3 - \\lambda\\right)\n",
    "$$\n",
    "\n",
    "There are three real-valued distinct eigenvalues $\\lambda_1 = 3,\\ \\lambda_2 = 1,\\ \\lambda_3 = 0$. For each the corresponding eigenvector is computed:\n",
    "\n",
    "**computing eigenvectors**\n",
    "\n",
    "For $\\lambda_1 = 3$ the elements of eigenvector $\\mathbf{v}_1$ are found solving this equation:\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{ccc}\n",
    "1-3 & 1 & 0 \\\\\n",
    "1 & 2-3 & 1 \\\\\n",
    "0 & 1 & 1-3\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{c}\n",
    "x_1 \\\\ x_2 \\\\ x_3\n",
    "\\end{array}\\right]\n",
    "= \\mathbf{0}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_1 = t \\cdot \\left[\\begin{array}{c}\n",
    "1 \\\\ 2 \\\\ 1\n",
    "\\end{array}\\right] = t \\cdot \\sqrt{6} \\cdot \\left[\\begin{array}{c}\n",
    "\\frac{1}{\\sqrt{6}} \\\\ \\frac{2}{\\sqrt{6}} \\\\ \\frac{1}{\\sqrt{6}}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "For $\\lambda_2 = 1$ the elements of eigenvector $\\mathbf{v}_2$ are found solving this equation:\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{ccc}\n",
    "1-1 & 1 & 0 \\\\\n",
    "1 & 2-1 & 1 \\\\\n",
    "0 & 1 & 1-1\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{c}\n",
    "x_1 \\\\ x_2 \\\\ x_3\n",
    "\\end{array}\\right]\n",
    "= \\mathbf{0}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_2 = t \\cdot \\left[\\begin{array}{c}\n",
    "-1 \\\\ 0 \\\\ 1\n",
    "\\end{array}\\right] = t \\cdot \\sqrt{2} \\cdot \\left[\\begin{array}{c}\n",
    "\\frac{-1}{\\sqrt{2}} \\\\ 0 \\\\ \\frac{1}{\\sqrt{2}}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "For $\\lambda_3 = 0$ the elements of eigenvector $\\mathbf{v}_3$ are found solving this equation:\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{ccc}\n",
    "1 & 1 & 0 \\\\\n",
    "1 & 2 & 1 \\\\\n",
    "0 & 1 & 1\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{c}\n",
    "x_1 \\\\ x_2 \\\\ x_3\n",
    "\\end{array}\\right]\n",
    "= \\mathbf{0}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_3 = t \\cdot \\left[\\begin{array}{c}\n",
    "1 \\\\ -1 \\\\ 1\n",
    "\\end{array}\\right] = t \\cdot \\sqrt{3} \\cdot \\left[\\begin{array}{c}\n",
    "\\frac{1}{\\sqrt{3}} \\\\ \\frac{-1}{\\sqrt{3}} \\\\ \\frac{1}{\\sqrt{3}}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "The eigenvectors $\\mathbf{v}_1,\\ \\mathbf{v}_2,\\ \\mathbf{v}_3$ have been computed as vectors each with length $1$ and a unknown scaling factor.\n",
    "\n",
    "Finally the orthogonal matrix $\\mathbf{V}$ can be setup with the orthonormal eigenvectorrs as column vectors.\n",
    "\n",
    "$$\n",
    "\\mathbf{V} = \\left[\\begin{array}{ccc}\n",
    "\\frac{1}{\\sqrt{6}} & \\frac{-1}{\\sqrt{2}} &  \\frac{1}{\\sqrt{3}} \\\\\n",
    "\\frac{2}{\\sqrt{6}} & 0 &  \\frac{-1}{\\sqrt{3}} \\\\\n",
    "\\frac{1}{\\sqrt{6}} & \\frac{1}{\\sqrt{2}} &  \\frac{1}{\\sqrt{3}}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "The column vectors of $\\mathbf{V}$ are mutually orthonormal. The inverse matrix $\\mathbf{V}^{-1}$ is just the transpose of $\\mathbf{V}$.\n",
    "\n",
    "Then the eigendecomposition of matrix $\\mathbf{A}^T \\cdot \\mathbf{A}$ may be written like this:\n",
    "\n",
    "$$\\begin{gather}\n",
    "\\mathbf{A}^T \\cdot \\mathbf{A} = \\mathbf{V} \\cdot \\Lambda \\cdot \\mathbf{V}^T \\\\\n",
    "\\mathbf{A}^T \\cdot \\mathbf{A} = \\left[\\begin{array}{ccc}\n",
    "\\frac{1}{\\sqrt{6}} & \\frac{-1}{\\sqrt{2}} &  \\frac{1}{\\sqrt{3}} \\\\\n",
    "\\frac{2}{\\sqrt{6}} & 0 &  \\frac{-1}{\\sqrt{3}} \\\\\n",
    "\\frac{1}{\\sqrt{6}} & \\frac{1}{\\sqrt{2}} &  \\frac{1}{\\sqrt{3}}\n",
    "\\end{array}\\right] \\cdot\n",
    "\\left[\\begin{array}{ccc}\n",
    "3 & 0 &  0 \\\\\n",
    "0 & 1 &  0 \\\\\n",
    "0 & 0 &  0\n",
    "\\end{array}\\right] \\cdot\n",
    "\\left[\\begin{array}{ccc}\n",
    "\\frac{1}{\\sqrt{6}} & \\frac{2}{\\sqrt{6}} &  \\frac{1}{\\sqrt{6}} \\\\\n",
    "\\frac{-1}{\\sqrt{2}} & 0 &  \\frac{1}{\\sqrt{2}} \\\\\n",
    "\\frac{1}{\\sqrt{3}} & \\frac{-1}{\\sqrt{3}} &  \\frac{1}{\\sqrt{3}}\n",
    "\\end{array}\\right] \n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "**summary**\n",
    "\n",
    "We have obtained the matrix $\\mathbf{V}$ as:\n",
    "\n",
    "$$\n",
    "\\mathbf{V} = \\left[\\begin{array}{ccc}\n",
    "\\frac{1}{\\sqrt{6}} & \\frac{2}{\\sqrt{6}} &  \\frac{1}{\\sqrt{6}} \\\\\n",
    "\\frac{-1}{\\sqrt{2}} & 0 &  \\frac{1}{\\sqrt{2}} \\\\\n",
    "\\frac{1}{\\sqrt{3}} & \\frac{-1}{\\sqrt{3}} &  \\frac{1}{\\sqrt{3}}\n",
    "\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "and the diagonal matrix $$\\left(\\mathbf{\\Sigma}^T \\cdot \\mathbf{\\Sigma}\\right)$$\n",
    "\n",
    "$$\n",
    "\\left(\\mathbf{\\Sigma}^T \\cdot \\mathbf{\\Sigma}\\right) = \\left[\\begin{array}{ccc}\n",
    "3 & 0 &  0 \\\\\n",
    "0 & 1 &  0 \\\\\n",
    "0 & 0 &  0\n",
    "\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "Then matrix $\\mathbf{\\Sigma}$ is a rectangular $2 \\times 3$ matrix.\n",
    "\n",
    "$$\n",
    "\\mathbf{\\Sigma} = \\left[\\begin{array}{ccc}\n",
    "\\sqrt{3} & 0 &  0 \\\\\n",
    "0 & 1 &  0 \\\\\n",
    "\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257d0ccb-2e6e-4056-8e9e-3fec4f0a14ba",
   "metadata": {},
   "source": [
    "To get orthonormal matrix $\\mathbf{U}$ we compute (manually) the eigendecomposition of $\\mathbf{A} \\cdot \\mathbf{A}^T$.\n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\cdot \\mathbf{A}^T = \n",
    "\\left[\\begin{array}{ccc}\n",
    "1 & 1 & 0 \\\\\n",
    "0 & 1 & 1\n",
    "\\end{array}\\right] \\cdot \\left[\\begin{array}{cc}\n",
    "1 & 0 \\\\\n",
    "1 & 1 \\\\\n",
    "0 & 1\n",
    "\\end{array}\\right] = \n",
    "\\left[\\begin{array}{cc}\n",
    "2 & 1 \\\\\n",
    "1 & 2\n",
    "\\end{array}\\right]\n",
    "$$ \n",
    "\n",
    "$$\n",
    "p(\\lambda) = det \\left[\\begin{array}{cc}\n",
    "2-\\lambda & 1 \\\\\n",
    "1 & 2-\\lambda \n",
    "\\end{array}\\right] =\\left(2 - \\lambda\\right)^2 -1 = 0\n",
    "$$\n",
    "\n",
    "Again eigenvalues $\\lambda_1 = 3$ and $\\lambda_2 = 1$ are found as solutions of the characteristic polynomial.\n",
    "\n",
    "**computing eigenvectors**\n",
    "\n",
    "For $\\lambda_1 = 3$ the elements of eigenvector $\\mathbf{u}_1$ is found as:\n",
    "\n",
    "$$\n",
    "\\mathbf{u}_1 = \n",
    "t \\cdot \\left[\\begin{array}{c}\n",
    "\\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "For $\\lambda_2 = 1$ the elements of eigenvector $\\mathbf{u}_2$ is found as:\n",
    "\n",
    "$$\n",
    "\\mathbf{u}_2 = \n",
    "t \\cdot \\left[\\begin{array}{c}\n",
    "\\frac{-1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "This gives us matrix $\\mathbf{U}$ as:\n",
    "\n",
    "$$\n",
    "\\mathbf{U} = \\frac{1}{\\sqrt{2}} \\cdot \\left[\\begin{array}{cc}\n",
    "1 & -1 \\\\\n",
    "1 & 1\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Finally all *ingredients* of the `SVD` are in place. Thus the matrix decomposition is written like this:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\mathbf{U} \\cdot \\mathbf{\\Sigma} \\cdot \\mathbf{V}^T = \\frac{1}{\\sqrt{2}} \\cdot \\left[\\begin{array}{cc}\n",
    "1 & -1 \\\\\n",
    "1 & 1\n",
    "\\end{array}\\right] \\cdot \n",
    "\\left[\\begin{array}{ccc}\n",
    "\\sqrt{3} & 0 &  0 \\\\\n",
    "0 & 1 &  0 \\\\\n",
    "\\end{array}\\right] \\cdot\n",
    "\\left[\\begin{array}{ccc}\n",
    "\\frac{1}{\\sqrt{6}} & \\frac{2}{\\sqrt{6}} &  \\frac{1}{\\sqrt{6}} \\\\\n",
    "\\frac{-1}{\\sqrt{2}} & 0 &  \\frac{1}{\\sqrt{2}} \\\\\n",
    "\\frac{1}{\\sqrt{3}} & \\frac{-1}{\\sqrt{3}} &  \\frac{1}{\\sqrt{3}}\n",
    "\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\mathbf{U} \\cdot \\mathbf{\\Sigma} \\cdot \\mathbf{V}^T = \\frac{1}{\\sqrt{2}} \\cdot \\left[\\begin{array}{cc}\n",
    "1 & -1 \\\\\n",
    "1 & 1\n",
    "\\end{array}\\right] \\cdot \n",
    "\\left[\\begin{array}{ccc}\n",
    "\\frac{1}{\\sqrt{2}}  & \\frac{2}{\\sqrt{2}} &  \\frac{1}{\\sqrt{2}} \\\\\n",
    "\\frac{-1}{\\sqrt{2}}  & 0 &  \\frac{1}{\\sqrt{2}}\n",
    "\\end{array}\\right] = \n",
    "\\left[\\begin{array}{cc}\n",
    "1 & -1 \\\\\n",
    "1 & 1\n",
    "\\end{array}\\right] \\cdot \n",
    "\\left[\\begin{array}{ccc}\n",
    "\\frac{1}{2}  & 1 &  \\frac{1}{2} \\\\\n",
    "\\frac{-1}{2}  & 0 &  \\frac{1}{2}\n",
    "\\end{array}\\right] =\n",
    "\\left[\\begin{array}{ccc}\n",
    "1 & 1 & 0 \\\\\n",
    "0 & 1 &  1 \n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "The example demonstrates that the `SVD` has indeed reproduced rectangular matrix $\\mathbf{A}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd5a191-3ee1-494a-b2d3-70462bf4126a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
